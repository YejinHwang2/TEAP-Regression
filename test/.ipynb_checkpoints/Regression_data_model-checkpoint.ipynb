{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c4d92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Generator\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torchmetrics as tm\n",
    "main_path = Path('..').resolve()\n",
    "sys.path.append(str(main_path))\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from typing import Dict\n",
    "\n",
    "from src.utils import RegressionMetricTaskRecorder, RegressionMetricRecorder\n",
    "from src.dataset import StockRegressionDataset, PanelDataDict\n",
    "from src.utils import ARGProcessor\n",
    "from src.model import PanelRegressionModel\n",
    "from src.trainer import Maml_Regression_Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9064c",
   "metadata": {},
   "source": [
    "## Data & Task generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15258fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(li: List[Any]) -> Generator:\n",
    "    \"\"\"flatten nested list\n",
    "    ```python\n",
    "    x = [[[1], 2], [[[[3]], 4, 5], 6], 7, [[8]], [9], 10]\n",
    "    print(type(flatten(x)))\n",
    "    # <generator object flatten at 0x00000212BF603CC8>\n",
    "    print(list(flatten(x)))\n",
    "    # [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    ```\n",
    "    Args:\n",
    "        li (List[Any]): any kinds of list\n",
    "    Yields:\n",
    "        Generator: flattened list generator\n",
    "    \"\"\"\n",
    "    for ele in li:\n",
    "        if isinstance(ele, list) or isinstance(ele, tuple):\n",
    "            yield from flatten(ele)\n",
    "        else:\n",
    "            yield ele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c6117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanelDataDict(dict):\n",
    "    def __init__(self, data, window_size):\n",
    "        self.window_size = window_size\n",
    "        self._set_state(f'numpy')\n",
    "        for k, v in data.items():\n",
    "            data[k] = np.array(v)\n",
    "        \n",
    "        self.n_stocks = len(v)\n",
    "        super().__init__(data)\n",
    "    \n",
    "    def tensor_fn(self, value, key):\n",
    "        return torch.FloatTensor(value)\n",
    "\n",
    "    def _set_state(self, state: str):\n",
    "        self.state = state\n",
    "\n",
    "    def to(self, device: None | str=None):\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        else:\n",
    "            device = torch.device(device)\n",
    "        self._set_state(f'tensor.{device}')\n",
    "        for key in self.keys():\n",
    "            value = self.__getitem__(key)\n",
    "            tvalue = self.tensor_fn(value, key)\n",
    "            self.__setitem__(key, tvalue.to(device)) \n",
    "        \n",
    "    def numpy(self):\n",
    "        self._set_state('numpy')\n",
    "        for key in self.keys():\n",
    "            tvalue = self.__getitem__(key)\n",
    "            if not isinstance(tvalue, np.ndarray): \n",
    "                self.__setitem__(key, tvalue.detach().numpy())\n",
    "\n",
    "    def __str__(self):\n",
    "        s = f'PanelDataDict(T={self.window_size}, {self.state})\\n'\n",
    "        for i, key in enumerate(self.keys()):\n",
    "            value = self.__getitem__(key)\n",
    "            s += f'- {key}: {value.shape}'\n",
    "            s += '' if i == len(self.keys())-1 else '\\n'\n",
    "        return s\n",
    "\n",
    "class StockRegressionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "            self, \n",
    "            meta_type: str ='train', \n",
    "            data_dir: Path | str ='', \n",
    "            dtype: str ='kdd17', \n",
    "            batch_size: int =64,\n",
    "            n_support: int =5, \n",
    "            n_query: int = 3,\n",
    "            test_window_size: List[int] =[15],\n",
    "            window_sizes: List[int] =[15]\n",
    "        ):    \n",
    "        \"\"\"dataset ref: https://arxiv.org/abs/1810.09936\n",
    "\n",
    "        In this meta learning setting, we have 3 meta-test and 1 meta-train\n",
    "        vertical = stocks, horizontal = time\n",
    "                train      |    test\n",
    "           A               |\n",
    "           B   meta-train  |   meta-test\n",
    "           C               |      (1)\n",
    "           ----------------|-------------\n",
    "           D   meta-test   |   meta-test\n",
    "           E     (2)       |      (3)\n",
    "\n",
    "        meta-test (1) same stock, different time\n",
    "        meta-test (2) different stock, same time\n",
    "        meta-test (3) different stock, different time\n",
    "        use `valid_date` to split the train / test set\n",
    "\n",
    "        the number of training stock was splitted with number of total stocks * 0.8.\n",
    "        we have 5 stock universe\n",
    "\n",
    "        Args:\n",
    "            meta_type (str, optional): _description_. Defaults to 'train'.\n",
    "            data_dir (Path | str, optional): _description_. Defaults to ''.\n",
    "            dtype (str, optional): _description_. Defaults to 'kdd17'.\n",
    "            stock_universe (int, optional): _description_. Defaults to 0.\n",
    "            batch_size (int, optional): Batch size. Number of stock x Number of timestamp that is aviable for each window size. Defaults to 64.\n",
    "            n_support (int, optional): Number of support. Defaults to 4.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # data config\n",
    "        self.data_dir = Path(data_dir).resolve()\n",
    "        ds_info = {\n",
    "            # train: (Jan-01-2007 to Jan-01-2015)\n",
    "            # val: (Jan-01-2015 to Jan-01-2016)\n",
    "            # test: (Jan-01-2016 to Jan-01-2017)\n",
    "            'kdd17': {\n",
    "                'path': self.data_dir / 'kdd17/price_long_50',\n",
    "                'date': self.data_dir / 'kdd17/trading_dates.csv',\n",
    "                'universe': self.data_dir / 'kdd17/stock_universe.json', \n",
    "                'start_date': '2007-01-01',\n",
    "                'train_date': '2015-01-01', \n",
    "                'valid_date': '2016-01-01', \n",
    "                'test_date': '2017-01-01',\n",
    "            },\n",
    "            # train: (Jan-01-2014 to Aug-01-2015)\n",
    "            # val: (Aug-01-2015 to Oct-01-2015)\n",
    "            # test: (Oct-01-2015 to Jan-01-2016)\n",
    "            'acl18': {\n",
    "                'path': self.data_dir / 'stocknet-dataset/price/raw',\n",
    "                'date': self.data_dir / 'stocknet-dataset/price/trading_dates.csv',\n",
    "                'universe': self.data_dir / 'stocknet-dataset/stock_universe.json',\n",
    "                'start_date': '2014-01-01',\n",
    "                'train_date': '2015-08-01', \n",
    "                'valid_date': '2015-10-01', \n",
    "                'test_date': '2016-01-01',\n",
    "            }\n",
    "        }\n",
    "        ds_config = ds_info[dtype]\n",
    "        \n",
    "        self.meta_type = meta_type\n",
    "        if meta_type in ['test-time', 'test-stock', 'test-mix']: \n",
    "            self.window_sizes = test_window_size\n",
    "        else:\n",
    "            self.window_sizes = window_size\n",
    "        self.batch_size = batch_size\n",
    "        self.n_support = n_support\n",
    "        self.n_query = n_query\n",
    "\n",
    "        # get data\n",
    "        self.data = {}\n",
    "        self.all_tasks = {}\n",
    "        ps = list((ds_config['path']).glob('*.csv'))\n",
    "        with ds_config['universe'].open('r') as file:\n",
    "            universe_dict = json.load(file)\n",
    "        \n",
    "        # meta_type: train / valid1: valid-time, valid2: valid-stock, valid3: valid-mix / test1, test2, test3\n",
    "        if meta_type in ['train', 'valid-time', 'test-time']:\n",
    "            universe = universe_dict['train']\n",
    "        elif meta_type in ['valid-stock', 'valid-mix']:\n",
    "            universe = universe_dict['valid']\n",
    "        elif meta_type in ['test-stock', 'test-mix']:\n",
    "            universe = universe_dict['test']\n",
    "        else:\n",
    "            raise KeyError('Error argument `meta_type`, should be in (train, valid-time, valid-stock, valid-mix, test-time, test-stock, test-mix)')\n",
    "\n",
    "        if meta_type in ['train', 'valid-stock', 'test-stock']:\n",
    "            date1 = ds_config['start_date']\n",
    "            date2 = ds_config['train_date']\n",
    "        elif meta_type in ['valid-time', 'valid-mix']:\n",
    "            date1 = ds_config['train_date']\n",
    "            date2 = ds_config['valid_date']\n",
    "        elif meta_type in ['test-time', 'test-mix']:\n",
    "            date1 = ds_config['valid_date']\n",
    "            date2 = ds_config['test_date']\n",
    "        else:\n",
    "            raise KeyError('Error argument `meta_type`, should be in (train, valid-time, valid-stock, valid-mix, test-time, test-stock, test-mix)')\n",
    "\n",
    "        iterator = [p for p in ps if p.name.strip('.csv') in universe]\n",
    "        for p in tqdm(iterator, total=len(iterator), desc=f'Processing data for {self.meta_type}'):    \n",
    "            stock_symbol = p.name.rstrip('.csv')\n",
    "            df_single = self.load_single_stock(p)\n",
    "            cond = df_single['date'].between(date1, date2)\n",
    "            df_single = df_single.loc[cond].reset_index(drop=True)\n",
    "            \n",
    "            self.data[stock_symbol] = df_single\n",
    "\n",
    "\n",
    "        self.n_stocks = len(universe)\n",
    "\n",
    "\n",
    "    def load_single_stock(self, p: Path | str):\n",
    "        def longterm_trend(x: pd.Series, k:int):\n",
    "            return (x.rolling(k).sum().div(k*x) - 1) * 100\n",
    "\n",
    "        df = pd.read_csv(p)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.sort_values('Date').reset_index(drop=True)\n",
    "        if 'Unnamed' in df.columns:\n",
    "            df.drop(columns=df.columns[7], inplace=True)\n",
    "        if 'Original_Open' in df.columns:\n",
    "            df.rename(columns={'Original_Open': 'Open', 'Open': 'Adj Open'}, inplace=True)\n",
    "\n",
    "        # Open, High, Low\n",
    "        z1 = (df.loc[:, ['Open', 'High', 'Low']].div(df['Close'], axis=0) - 1).rename(\n",
    "            columns={'Open': 'open', 'High': 'high', 'Low': 'low'}) * 100\n",
    "        # Close\n",
    "        z2 = df[['Close']].pct_change().rename(columns={'Close': 'close'}) * 100\n",
    "        # Adj Close\n",
    "        z3 = df[['Adj Close']].pct_change().rename(columns={'Adj Close': 'adj_close'}) * 100\n",
    "\n",
    "        z4 = []\n",
    "        for k in [5, 10, 15, 20, 25, 30]:\n",
    "            z4.append(df[['Adj Close']].apply(longterm_trend, k=k).rename(columns={'Adj Close': f'zd{k}'}))\n",
    "\n",
    "        df_pct = pd.concat([df['Date'], z1, z2, z3] + z4, axis=1).rename(columns={'Date': 'date'})\n",
    "        cols_max = df_pct.columns[df_pct.isnull().sum() == df_pct.isnull().sum().max()]\n",
    "        df_pct = df_pct.loc[~df_pct[cols_max].isnull().values, :]\n",
    "\n",
    "        return df_pct\n",
    "\n",
    "    def sliding_window_idx(self, df_single, window_size):\n",
    "    \n",
    "        if len(df_single) >= window_size:\n",
    "            x_spt_task = []\n",
    "            y_spt_task = []\n",
    "            x_qry_task = []\n",
    "            y_qry_task = []\n",
    "\n",
    "            for i in range(len(df_single)-window_size-self.n_support-self.n_query+1):\n",
    "                x_spt = []\n",
    "                y_spt = []\n",
    "                x_qry = []\n",
    "                y_qry = []\n",
    "\n",
    "                for j in range(self.n_support+self.n_query):\n",
    "                    if j < self.n_support:\n",
    "                        spt_idx = [idx for idx in range(i+j, i+j+window_size)]\n",
    "                        x_spt.append(spt_idx)\n",
    "                        y_spt.append(i+j+window_size)\n",
    "\n",
    "                    else:\n",
    "                        qry_idx = [idx for idx in range(i+j, i+j+window_size)]\n",
    "                        x_qry.append(qry_idx)\n",
    "                        y_qry.append(i+j+window_size)\n",
    "\n",
    "                x_spt_task.append(x_spt)\n",
    "                y_spt_task.append(y_spt)\n",
    "                x_qry_task.append(x_qry)\n",
    "                y_qry_task.append(y_qry)\n",
    "            return x_spt_task, y_spt_task, x_qry_task, y_qry_task\n",
    "    \n",
    "    def generate_data(self,df_single, x_spt_task, y_spt_task, x_qry_task, y_qry_task):\n",
    "        num_task = len(x_spt_task)\n",
    "        support_task = []\n",
    "        support_labels = []\n",
    "        query_task = []\n",
    "        query_labels = []\n",
    "        for i in range(num_task):\n",
    "            support_inputs = []\n",
    "            query_inputs = []\n",
    "            for j in range(self.n_support):\n",
    "                support_inputs.append(df_single.iloc[x_spt_task[i][j]].to_numpy()[:, 1:].astype(np.float64))\n",
    "\n",
    "            support_labels.append(df_single['close'].iloc[y_spt_task[i]].to_numpy().astype(np.float64))\n",
    "            support_task.append(np.array(support_inputs))\n",
    "            for k in range(self.n_query):\n",
    "                query_inputs.append(df_single.iloc[x_qry_task[i][k]].to_numpy()[:, 1:].astype(np.float64))\n",
    "            query_labels.append(df_single['close'].iloc[y_qry_task[i]].to_numpy().astype(np.float64))\n",
    "            query_task.append(np.array(query_inputs))   \n",
    "\n",
    "        return support_task, support_labels, query_task, query_labels\n",
    "    \n",
    "    @property\n",
    "    def symbols(self):\n",
    "        return list(self.data.keys())\n",
    "    \n",
    "    def generate_all_task(self):\n",
    "        all_tasks = dict()\n",
    "        for window in self.window_sizes:\n",
    "            all_tasks[window] = self.generate_all_task_per_window(window)\n",
    "        self.all_tasks = all_tasks\n",
    "\n",
    "    def generate_all_task_per_window(self,window_size):\n",
    "        \n",
    "        all_window_tasks = dict(\n",
    "                query = [],\n",
    "                query_labels = [],\n",
    "                support = [],\n",
    "                support_labels = [],\n",
    "            )\n",
    "        for symbol in self.symbols:\n",
    "            df = self.data[symbol]\n",
    "            x_spt_task, y_spt_task, x_qry_task, y_qry_task = self.sliding_window_idx(df, window_size)\n",
    "            support_inputs, support_labels, query_inputs, query_labels = self.generate_data(df, x_spt_task, y_spt_task, x_qry_task, y_qry_task)\n",
    "            all_window_tasks['query'].extend(query_inputs)\n",
    "            all_window_tasks['query_labels'].extend(query_labels)\n",
    "            all_window_tasks['support'].extend(support_inputs)\n",
    "            all_window_tasks['support_labels'].extend(support_labels)\n",
    "        \n",
    "        all_window_tasks['query'] = np.array(all_window_tasks['query'])\n",
    "        all_window_tasks['query_labels'] = np.array(all_window_tasks['query_labels'])\n",
    "        all_window_tasks['support'] = np.array(all_window_tasks['support'])\n",
    "        all_window_tasks['support_labels'] = np.array(all_window_tasks['support_labels'])\n",
    "        return all_window_tasks\n",
    "    \n",
    "    def generate_batch_task(self, all_tasks):\n",
    "        batch_tasks = dict(\n",
    "                query = [],\n",
    "                query_labels = [],\n",
    "                support = [],\n",
    "                support_labels = [],\n",
    "            )\n",
    "\n",
    "        \n",
    "        if len(self.window_sizes) > 1:\n",
    "            window_size = random.choice(self.window_sizes)\n",
    "        else:\n",
    "            window_size = self.window_sizes[0]\n",
    "               \n",
    "        num_task = len(all_tasks[window_size]['query'])\n",
    "        batch_idx = random.sample(list(range(num_task)), self.batch_size)\n",
    "        batch_tasks['query'] = all_tasks[window_size]['query'][batch_idx]\n",
    "        batch_tasks['query_labels'] = all_tasks[window_size]['query_labels'][batch_idx]\n",
    "        batch_tasks['support'] = all_tasks[window_size]['support'][batch_idx]\n",
    "        batch_tasks['support_labels'] = all_tasks[window_size]['support_labels'][batch_idx]\n",
    "\n",
    "        return batch_tasks, window_size\n",
    "\n",
    "    def update_q_idx_dist(self, q_target):\n",
    "        self.q_dist[q_target] += 1\n",
    "\n",
    "    def reset_q_idx_dist(self):\n",
    "        self.q_dist = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e138a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../TEAP/data\"\n",
    "dtype = \"kdd17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c575ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(data_dir).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "619aadd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/yjhwang/TEAP/data')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68fd8bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = [15] \n",
    "test_window_size = [15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3777f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data for train: 100%|██████████| 35/35 [00:01<00:00, 17.76it/s]\n",
      "Processing data for valid-time: 100%|██████████| 35/35 [00:02<00:00, 17.27it/s]\n",
      "Processing data for valid-stock: 100%|██████████| 10/10 [00:00<00:00, 41.64it/s]\n",
      "Processing data for valid-mix: 100%|██████████| 10/10 [00:00<00:00, 42.24it/s]\n",
      "Processing data for test-time: 100%|██████████| 35/35 [00:01<00:00, 19.93it/s]\n",
      "Processing data for test-stock: 100%|██████████| 5/5 [00:00<00:00, 15.39it/s]\n",
      "Processing data for test-mix: 100%|██████████| 5/5 [00:00<00:00, 15.15it/s]\n"
     ]
    }
   ],
   "source": [
    "meta_train = StockRegressionDataset(data_dir = data_dir, n_query = 1, window_sizes = window_size, test_window_size = test_window_size)\n",
    "meta_valid_time = StockRegressionDataset(meta_type='valid-time', data_dir = data_dir, n_query = 1, window_sizes = window_size, test_window_size = test_window_size)\n",
    "meta_valid_entity = StockRegressionDataset(meta_type='valid-stock', data_dir = data_dir, n_query = 1, window_sizes = window_size, test_window_size = test_window_size)\n",
    "meta_valid_mix = StockRegressionDataset(meta_type='valid-mix', data_dir = data_dir, n_query = 1, window_sizes = window_size, test_window_size = test_window_size)\n",
    "meta_test_time = StockRegressionDataset(meta_type='test-time', data_dir = data_dir, n_query = 1, window_sizes = window_size, test_window_size = test_window_size)\n",
    "meta_test_entity = StockRegressionDataset(meta_type='test-stock', data_dir = data_dir, n_query = 1, window_sizes = window_size, test_window_size = test_window_size)\n",
    "meta_test_mix = StockRegressionDataset(meta_type='test-mix', data_dir = data_dir, n_query = 1, window_sizes = window_size, test_window_size = test_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d71c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_train.generate_all_task()\n",
    "meta_valid_time.generate_all_task()\n",
    "meta_valid_entity.generate_all_task()\n",
    "meta_valid_mix.generate_all_task()\n",
    "meta_test_time.generate_all_task()\n",
    "meta_test_entity.generate_all_task()\n",
    "meta_test_mix.generate_all_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c49ec8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_test_mix.generate_all_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4003587b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([15])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test_mix.all_tasks.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9334548",
   "metadata": {},
   "source": [
    "## MetricRecorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a88d7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionMetricRecorder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        cs = tm.MetricCollection({\n",
    "            'Support_MSE': tm.MeanMetric(), \n",
    "            'Support_MAE': tm.MeanMetric(),\n",
    "            'Support_MAPE': tm.MeanMetric(),\n",
    "            'Query_MSE': tm.MeanMetric(), \n",
    "            'Query_MAE': tm.MeanMetric(),\n",
    "            'Query_MAPE': tm.MeanMetric(),\n",
    "        })\n",
    "\n",
    "        self.metrics = cs.clone()\n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self.metrics.keys())\n",
    "    \n",
    "    def update(self, key, scores):\n",
    "        self.metrics[key].update(scores)\n",
    "            \n",
    "    def compute(self, prefix: str):\n",
    "        results = {}\n",
    "        for k in self.keys:\n",
    "            m = self.metrics[k].compute()\n",
    "            if isinstance(m, torch.Tensor):\n",
    "                m = m.cpu().detach().numpy()\n",
    "            results[f'{prefix}-{k}'] = m\n",
    "        return results\n",
    "    \n",
    "    def reset(self):\n",
    "        for k in self.keys:\n",
    "            self.metrics[k].reset()\n",
    "            \n",
    "class RegressionMetricTaskRecorder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        cs = tm.MetricCollection({\n",
    "            'Support_MSE': tm.MeanSquaredError(), \n",
    "            'Support_MAE': tm.MeanAbsoluteError(),\n",
    "            'Support_MAPE': tm.MeanAbsolutePercentageError(),\n",
    "            'Query_MSE': tm.MeanSquaredError(), \n",
    "            'Query_MAE': tm.MeanAbsoluteError(),\n",
    "            'Query_MAPE': tm.MeanAbsolutePercentageError(),\n",
    "        })\n",
    "        \n",
    "        self.metrics = cs.clone()\n",
    "        \n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self.metrics.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bfc4da",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0865818",
   "metadata": {},
   "source": [
    "## Single Step ALSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a645ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.lnorm = nn.LayerNorm(hidden_size)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (B, T, I)\n",
    "        o, (h, _) = self.lstm(x) # o: (B, T, H) / h: (1, B, H)\n",
    "        normed_context = self.lnorm(h[-1, :, :])\n",
    "        return normed_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0efe08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMAttention(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=False)\n",
    "        self.lnorm = nn.LayerNorm(hidden_size)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, rt_attn: bool=False):\n",
    "        # x: (B, T, I)\n",
    "        o, (h, _) = self.lstm(x) # o: (B, T, H) / h: (1, B, H)\n",
    "        h = h[-1, :, :]  # (B, H)\n",
    "        score = torch.bmm(o, h.unsqueeze(-1)) # (B, T, H) x (B, H, 1)\n",
    "        attn = torch.softmax(score, 1).squeeze(-1)  # (B, T)\n",
    "        context = torch.bmm(attn.unsqueeze(1), o).squeeze(1)  # (B, 1, T) x (B, T, H)\n",
    "        normed_context = self.lnorm(context)  # (B, H)\n",
    "        if rt_attn:\n",
    "            return normed_context, attn\n",
    "        else:\n",
    "            return normed_context, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5bf1200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PanelRegressionModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_size: int, \n",
    "        embed_size: int,\n",
    "        output_size: int,\n",
    "        num_layers: int, \n",
    "        drop_rate: float, \n",
    "        device: str\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Network\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "        self.lstm_encoder = LSTMAttention(input_size=feature_size, hidden_size=embed_size, num_layers=num_layers)\n",
    "        self.layer_norm = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(embed_size, output_size),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "\n",
    "\n",
    "        # Loss\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "        # Meta Mode Support / Query\n",
    "        self._mode_query(False)\n",
    "\n",
    "    # Recoder\n",
    "    # self.recorder = MetricRecorder().to(device)\n",
    "\n",
    "    def meta_train(self):\n",
    "        self.train()\n",
    "\n",
    "    def meta_eval(self):\n",
    "        self.manual_model_eval()\n",
    "\n",
    "    def _mode_query(self, mode: bool=True):\n",
    "        # check if is support of query\n",
    "        self.is_query = mode\n",
    "\n",
    "    def manual_model_eval(self, mode: bool=False):\n",
    "        \"\"\"\n",
    "        [PyTorch Issue] RuntimeError: cudnn RNN backward can only be called in training mode\n",
    "        cannot use `model.eval()`. \n",
    "        see https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch\n",
    "        \"\"\"\n",
    "        for module in self.children():\n",
    "            self.training = mode\n",
    "            if isinstance(module, nn.Dropout) or isinstance(module, nn.LayerNorm):\n",
    "                module.train(mode)\n",
    "\n",
    "    def encode_lstm(self, inputs: torch.Tensor, rt_attn: bool=False):\n",
    "        \"\"\"forward data by each stock to avoid trained by other stocks\n",
    "        - B: number of samples (n_support if meta-learning)\n",
    "        - T: window size\n",
    "        - I: input size\n",
    "        - E: embedding size\n",
    "        - M: M = N * K\n",
    "\n",
    "        Args:\n",
    "            inputs: (B, T, I).\n",
    "            - support: (B, T, I) B: n_support\n",
    "            - query: (B, T, I) B: n_query\n",
    "\n",
    "        Returns:\n",
    "            encoded: (B, E)\n",
    "            attn: (B, T)\n",
    "        \"\"\"\n",
    "        B, T, I = inputs.size() # B = n_support\n",
    "        inputs = self.dropout(inputs)\n",
    "        encoded, attn = self.lstm_encoder(inputs, rt_attn)  # encoded: (B, E), attn: (B, T)\n",
    "        encoded = self.layer_norm(encoded)\n",
    "        return encoded, attn\n",
    "\n",
    "    def forward_encoder(self, inputs: torch.Tensor, rt_attn: bool=True):\n",
    "        \"\"\"Forward Encoder: from `inputs` to `z`\n",
    "        - B: number of n_support\n",
    "        - T: window size\n",
    "        - E: embedding size\n",
    "        - H: hidden size\n",
    "\n",
    "        Returns:\n",
    "            l: (B, O) # O: output feature dim\n",
    "            attn: (B, T). attention weights for each inputs.\n",
    "\n",
    "        \"\"\"\n",
    "        # support l: (B, T, E), attn: (B, T)\n",
    "        # query l: (B, T, E), attn: (B, T)\n",
    "\n",
    "        l, attn = self.encode_lstm(inputs, rt_attn=rt_attn)\n",
    "        e = self.encoder(l)  # e: (B, N, K, 2)\n",
    "\n",
    "        return e, attn\n",
    "\n",
    "    def forward(\n",
    "            self, data , # data = torch.tensor\n",
    "            rt_attn: bool=False\n",
    "        ):\n",
    "\n",
    "        e , attn = self.forward_encoder(data) # e: (B, O)\n",
    "        e = e.squeeze(dim=-1)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3916d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size: 11 \n",
    "embed_size: 32\n",
    "output_size: 1\n",
    "num_layers: 1 \n",
    "drop_rate: 0.1\n",
    "device: 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6edff31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PanelRegressionModel(feature_size=11, embed_size=32, output_size=1, num_layers=1, drop_rate=0, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95481b68",
   "metadata": {},
   "source": [
    "## MAML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19a72614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maml_Regression_Trainer(nn.Module):\n",
    "    def __init__(\n",
    "        self, exp_name, log_dir, task_type,  model, batch_size,\n",
    "        n_inner_step, total_steps, \n",
    "        n_valid_step, every_valid_step, print_step,\n",
    "        inner_lr, outer_lr, device, clip_value, test_window_size):\n",
    "        \n",
    "        super(Maml_Regression_Trainer, self).__init__()\n",
    "        self.exp_name = exp_name\n",
    "        self.log_dir = Path(log_dir).resolve()\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        if task_type == \"classification\":\n",
    "            self.loss_fn = nn.NLLLoss() \n",
    "        elif task_type == \"regression\":\n",
    "            self.loss_fn = nn.MSELoss()\n",
    "            \n",
    "        self.n_inner_step = n_inner_step\n",
    "        self.total_steps = total_steps\n",
    "        self.n_valid_step = n_valid_step\n",
    "        self.every_valid_step = every_valid_step\n",
    "        self.print_step = print_step\n",
    "        self.inner_lr = inner_lr\n",
    "        self.outer_lr = outer_lr\n",
    "        self.batch_size = batch_size\n",
    "        self.test_window_size = test_window_size[0]\n",
    "        self.keep_weights = self.clone_weight(self.model)\n",
    "        self.meta_optim = torch.optim.Adam(\n",
    "            self.model.parameters(), \n",
    "            lr=self.outer_lr\n",
    "        )\n",
    "        if self.device == 'cuda':\n",
    "            self.cuda()\n",
    "        \n",
    "        # Recoder\n",
    "        self.train_recorder = RegressionMetricRecorder().to(device)\n",
    "        self.valid_recorder = RegressionMetricRecorder().to(device)\n",
    "        self.test_recorder = RegressionMetricRecorder().to(device)\n",
    "        \n",
    "        self.task_recorder = RegressionMetricTaskRecorder().to(device)\n",
    " \n",
    "\n",
    "        \n",
    "    def init_experiments(self, exp_num=None, record_tensorboard: bool=True):\n",
    "        # check if exp exists\n",
    "        exp_dirs = sorted(list(self.log_dir.glob(f'{self.exp_name}_*')))\n",
    "        if exp_num is None:\n",
    "            exp_num = int(exp_dirs[-1].name[len(self.exp_name)+1:]) if exp_dirs else 0\n",
    "            self.exp_num = exp_num + 1\n",
    "        else:\n",
    "            self.exp_num = exp_num\n",
    "        self.exp_dir = self.log_dir / f'{self.exp_name}_{self.exp_num}'\n",
    "        if record_tensorboard:\n",
    "            self.writer = SummaryWriter(str(self.exp_dir))\n",
    "        else:\n",
    "            self.writer = None\n",
    "        self.ckpt_path = self.exp_dir / 'checkpoints'\n",
    "        self.ckpt_step_train_path =  self.ckpt_path / 'step' / 'train'\n",
    "        self.ckpt_step_valid_path =  self.ckpt_path / 'step' / 'valid'\n",
    "        for p in [self.ckpt_path, self.ckpt_step_train_path, self.ckpt_step_valid_path]:\n",
    "            if not p.exists():\n",
    "                p.mkdir(parents=True)    \n",
    "    \n",
    "    def get_acc(self,y_true, y_pred):\n",
    "        correct = torch.eq(y_pred, y_true).sum().item()\n",
    "        acc = correct/ len(y_true)\n",
    "        return acc\n",
    "\n",
    "    def clone_weight(self, model):\n",
    "        return {k: v.clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    def meta_update(self, dummy_loss, sum_grads):\n",
    "        # Update theta_parameter by sum_gradients\n",
    "        hooks = []\n",
    "        for k,v in enumerate(self.model.parameters()):\n",
    "            def closure():\n",
    "                key = k\n",
    "                return lambda grad: sum_grads[key]\n",
    "            hooks.append(v.register_hook(closure()))\n",
    "\n",
    "        self.meta_optim.zero_grad()\n",
    "        dummy_loss.backward()\n",
    "        self.meta_optim.step()\n",
    "\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "                \n",
    "    # inner loop per 1 task\n",
    "    def inner_loop(self, support_x, support_y, query_x, query_y, is_meta_train):\n",
    "        updated_state_dict = {k: v.clone() for k, v in self.keep_weights.items()}\n",
    "        for i in range(self.n_inner_step):\n",
    "            if i > 0:\n",
    "                self.model.load_state_dict(updated_state_dict)\n",
    "            support_e = self.model(support_x)\n",
    "            s_loss = self.loss_fn(support_e, support_y)\n",
    "            grad = torch.autograd.grad(\n",
    "                    s_loss, \n",
    "                    self.model.parameters(),\n",
    "                    create_graph=True,\n",
    "                )\n",
    "            for i, (k,w) in enumerate(updated_state_dict.items()):\n",
    "                updated_state_dict[k] = updated_state_dict[k] - self.inner_lr * grad[i].data\n",
    "        \n",
    "        s_mse = self.task_recorder.metrics['Support_MSE'](support_e, support_y)\n",
    "        s_mae = self.task_recorder.metrics['Support_MAE'](support_e, support_y)\n",
    "        s_mape = self.task_recorder.metrics['Support_MAPE'](support_e, support_y)\n",
    "       \n",
    "        self.model.load_state_dict(updated_state_dict)\n",
    "        query_e = self.model(query_x)\n",
    "        q_loss = self.loss_fn(query_e, query_y)\n",
    "        \n",
    "        q_mse = self.task_recorder.metrics['Query_MSE'](query_e, query_y)\n",
    "        q_mae = self.task_recorder.metrics['Query_MAE'](query_e, query_y)\n",
    "        q_mape = self.task_recorder.metrics['Query_MAPE'](query_e, query_y)\n",
    "        \n",
    "        \n",
    "        if is_meta_train:\n",
    "            q_grad = torch.autograd.grad(q_loss, self.model.parameters(), create_graph=True)\n",
    "        else:\n",
    "            q_grad = None\n",
    "        \n",
    "        \n",
    "        return s_mse, s_mae, s_mape, q_mse, q_mae, q_mape, q_grad, query_e\n",
    "\n",
    "    # outer loop per batch\n",
    "    def outer_loop(self, meta_dataset):\n",
    "        self.model.meta_train()\n",
    "        batch_task, window_size = meta_dataset.generate_batch_task(all_tasks=meta_dataset.all_tasks) # PanelDataDict\n",
    "        train_tasks  = PanelDataDict(batch_task,window_size = window_size)\n",
    "        train_tasks.to(self.device)\n",
    "        all_q_grads = []\n",
    "\n",
    "        self.keep_weights = self.clone_weight(self.model)\n",
    "        \n",
    "        for i  in range(self.batch_size):\n",
    "            x_spt = train_tasks['support'][i]\n",
    "            y_spt = train_tasks['support_labels'][i]\n",
    "            x_qry = train_tasks['query'][i]\n",
    "            y_qry = train_tasks['query_labels'][i]\n",
    "            s_mse, s_mae, s_mape, q_mse, q_mae, q_mape, q_grad, query_e = self.inner_loop(x_spt, y_spt, x_qry, y_qry, is_meta_train=True)\n",
    "            self.train_recorder.update('Support_MSE', s_mse)\n",
    "            self.train_recorder.update('Support_MAE', s_mae)\n",
    "            self.train_recorder.update('Support_MAPE', s_mape)\n",
    "            self.train_recorder.update('Query_MSE', q_mse)\n",
    "            self.train_recorder.update('Query_MAE', q_mae)\n",
    "            self.train_recorder.update('Query_MAPE', q_mape)\n",
    "            \n",
    "            \n",
    "            all_q_grads.append(q_grad)\n",
    "            self.model.load_state_dict(self.keep_weights)\n",
    "            \n",
    "        \n",
    "        sum_q_grads = [torch.stack(grads).sum(dim=0) for grads in list(zip(*all_q_grads))]\n",
    "        \n",
    "        x_spt = train_tasks['support'][0]\n",
    "        y_spt = train_tasks['support_labels'][0]\n",
    "        \n",
    "        dummy_e = self.model(x_spt)\n",
    "        dummy_loss = self.loss_fn(dummy_e, y_spt)\n",
    "        \n",
    "        self.meta_update(dummy_loss, sum_q_grads)\n",
    "        return \n",
    "\n",
    "\n",
    "    def meta_train(self, meta_trainset,\n",
    "                meta_validset_time,\n",
    "                meta_validset_entity,\n",
    "                meta_validset_mix, \n",
    "                print_log: bool=True):\n",
    "        \n",
    "        best_eval_mse = 10000.0\n",
    "        for step in range(self.total_steps):\n",
    "            self.train_recorder.reset()\n",
    "            # Meta-Train per epoch\n",
    "            self.outer_loop(meta_trainset)\n",
    "            if ( step % self.print_step == 0) or (step == self.total_steps-1):\n",
    "                prefix = 'Train'\n",
    "                train_logs = self.train_recorder.compute(prefix)\n",
    "                cur_eval_mse = train_logs[f'{prefix}-Query_MSE']\n",
    "                cur_eval_mae = train_logs[f'{prefix}-Query_MAE']\n",
    "                cur_eval_mape = train_logs[f'{prefix}-Query_MAPE']\n",
    "                \n",
    "                self.log_results(train_logs, prefix, step=step, total_steps=self.total_steps, print_log=True)\n",
    "                torch.save(self.model.state_dict(), str(self.ckpt_step_train_path / f'{step}-{cur_eval_mse:.4f}.ckpt'))\n",
    "\n",
    "                \n",
    "            # Meta-Valid\n",
    "            if (self.every_valid_step != 0):\n",
    "                if (step % self.every_valid_step == 0) or (step == self.total_steps-1):\n",
    "                    ref_step = step\n",
    "                    \n",
    "                    prefix = 'Valid-time'\n",
    "                    valid_time_logs, cur_eval_mse_time, cur_eval_mae_time, cur_eval_mape_time = self.meta_valid(self.model, meta_validset_time, prefix, ref_step, self.n_valid_step)\n",
    "                    \n",
    "                    prefix = 'Valid-entity'\n",
    "                    valid_entity_logs, cur_eval_mse_entity, cur_eval_mae_entity, cur_eval_mape_entity = self.meta_valid(self.model, meta_validset_entity, prefix, ref_step, self.n_valid_step)\n",
    "                    \n",
    "                    prefix = 'Valid-mix'\n",
    "                    valid_mix_logs, cur_eval_mse_mix, cur_eval_mae_mix, cur_eval_mape_mix = self.meta_valid(self.model, meta_validset_mix, prefix, ref_step, self.n_valid_step)\n",
    "                    \n",
    "                    prefix = 'Valid'\n",
    "                    cur_eval_mse = (cur_eval_mse_time + cur_eval_mse_entity + cur_eval_mse_mix) / 3\n",
    "                    cur_eval_mae = (cur_eval_mae_time + cur_eval_mae_entity + cur_eval_mae_mix) / 3\n",
    "                    cur_eval_mape = (cur_eval_mape_time + cur_eval_mape_entity + cur_eval_mape_mix) / 3\n",
    "                    valid_final_log = {f'{prefix}-AvgMSE': cur_eval_mse, f'{prefix}-AvgMAE': cur_eval_mae, f'{prefix}-AvgMAPE': cur_eval_mape}\n",
    "                    self.log_results(valid_final_log, prefix, step=ref_step, total_steps=self.total_steps, print_log=print_log)\n",
    "                    \n",
    "                    # save best\n",
    "                    if (cur_eval_mse < best_eval_mse):\n",
    "                        best_eval_mse = cur_eval_mse \n",
    "                        torch.save(self.model.state_dict(), str(self.ckpt_step_valid_path / f'{ref_step:06d}-{cur_eval_mse:.4f}.ckpt'))\n",
    "                    \n",
    "    def meta_valid(self, model, meta_dataset, prefix, ref_step, n_valid, print_log=True):\n",
    "        self.valid_recorder.reset()\n",
    "        valid_logs = self.run_valid(model, meta_dataset, n_valid, prefix)\n",
    "        self.log_results(valid_logs, prefix, step=ref_step, total_steps=self.total_steps, print_log=print_log)\n",
    "        cur_eval_mse = valid_logs[f'{prefix}-Query_MSE']\n",
    "        cur_eval_mae = valid_logs[f'{prefix}-Query_MAE']\n",
    "        cur_eval_mape = valid_logs[f'{prefix}-Query_MAPE']\n",
    "        return valid_logs, cur_eval_mse, cur_eval_mae, cur_eval_mape\n",
    "        \n",
    "    def meta_test(self, model, meta_dataset,  print_log: bool=True):\n",
    "        self.test_recorder.reset()\n",
    "        prefix = meta_dataset.meta_type.capitalize()\n",
    "        test_logs = self.run_test(model, meta_dataset, prefix)\n",
    "        self.log_results(test_logs, prefix, step=0, total_steps=0, print_log=print_log)\n",
    "        eval_mse = test_logs[f'{prefix}-Query_MSE']\n",
    "        eval_mae = test_logs[f'{prefix}-Query_MAE']\n",
    "        eval_mape = test_logs[f'{prefix}-Query_MAPE']\n",
    "        return prefix, eval_mse, eval_mae, eval_mape\n",
    "    \n",
    "    def run_valid(self, model, meta_dataset, n_valid, prefix):\n",
    "        model = model.to(self.device)\n",
    "        model.meta_eval()\n",
    "        pregress = tqdm(range(n_valid), total= n_valid, desc=f'Running {prefix}')\n",
    "     \n",
    "        for val_idx in pregress:\n",
    "            batch_task, window_size = meta_dataset.generate_batch_task(all_tasks=meta_dataset.all_tasks) # PanelDataDict\n",
    "            valid_tasks  = PanelDataDict(batch_task,window_size = window_size)\n",
    "            valid_tasks.to(self.device)\n",
    "            for i  in range(self.batch_size):\n",
    "                x_spt = valid_tasks['support'][i]\n",
    "                y_spt = valid_tasks['support_labels'][i]\n",
    "                x_qry = valid_tasks['query'][i]\n",
    "                y_qry = valid_tasks['query_labels'][i]\n",
    "                s_mse, s_mae, s_mape, q_mse, q_mae, q_mape, q_grad, query_e = self.inner_loop(x_spt, y_spt, x_qry, y_qry, is_meta_train=False)\n",
    "                self.valid_recorder.update('Support_MSE', s_mse)\n",
    "                self.valid_recorder.update('Support_MAE', s_mae)\n",
    "                self.valid_recorder.update('Support_MAPE', s_mape)\n",
    "                self.valid_recorder.update('Query_MSE', q_mse)\n",
    "                self.valid_recorder.update('Query_MAE', q_mae)\n",
    "                self.valid_recorder.update('Query_MAPE', q_mape)\n",
    "        \n",
    "        \n",
    "        pregress.close()\n",
    "        valid_logs = self.valid_recorder.compute(prefix)       \n",
    "        return valid_logs\n",
    "    \n",
    "    def run_test(self, model, meta_dataset, prefix):\n",
    "        model = model.to(self.device)\n",
    "        model.meta_eval()\n",
    "        test_all_tasks = meta_dataset.all_tasks[self.test_window_size]\n",
    "        test_tasks = PanelDataDict(test_all_tasks, window_size = self.test_window_size)\n",
    "        test_tasks.to(self.device)\n",
    "        pregress = tqdm(range(len(test_tasks['query'])), total= len(test_tasks['query']), desc=f'Running {prefix}')\n",
    "        for test_idx in pregress:\n",
    "            x_spt = test_tasks['support'][test_idx]\n",
    "            y_spt = test_tasks['support_labels'][test_idx]\n",
    "            x_qry = test_tasks['query'][test_idx]\n",
    "            y_qry = test_tasks['query_labels'][test_idx]\n",
    "            s_mse, s_mae, s_mape, q_mse, q_mae, q_mape, q_grad, query_e = self.inner_loop(x_spt, y_spt, x_qry, y_qry, is_meta_train=False)\n",
    "            self.test_recorder.update('Support_MSE', s_mse)\n",
    "            self.test_recorder.update('Support_MAE', s_mae)\n",
    "            self.test_recorder.update('Support_MAPE', s_mape)\n",
    "            self.test_recorder.update('Query_MSE', q_mse)\n",
    "            self.test_recorder.update('Query_MAE', q_mae)\n",
    "            self.test_recorder.update('Query_MAPE', q_mape)\n",
    "        \n",
    "        pregress.close()\n",
    "        test_logs = self.test_recorder.compute(prefix)       \n",
    "        return test_logs\n",
    "    \n",
    "    def log_results(self, logs, prefix, step, total_steps, print_log=False):\n",
    "        \n",
    "        for log_string, value in logs.items():       \n",
    "            if self.writer is not None:\n",
    "                self.writer.add_scalar(log_string, value, step)\n",
    "                \n",
    "        def extract(prefix, key, logs):\n",
    "            mean = logs[f'{prefix}-{key}']\n",
    "            s = ''\n",
    "            s += f'{mean:.4f}'\n",
    "            return s\n",
    "\n",
    "        if print_log:\n",
    "            only_one_to_print = True if prefix in ['Valid', 'Test'] else False\n",
    "\n",
    "            if only_one_to_print:\n",
    "                avgmse = extract(prefix, 'AvgMSE', logs)\n",
    "                avgmae = extract(prefix, 'AvgMAE', logs)\n",
    "                avgmape = extract(prefix, 'AvgMAPE', logs)\n",
    "         \n",
    "                print(f'[Meta {prefix}] Result - AvgMSE: {avgmse}, AvgMAE: {avgmae}, AvgMAPE: {avgmape} ')\n",
    "                print()\n",
    "\n",
    "            else:\n",
    "                s_mse = extract(prefix, 'Support_MSE', logs)\n",
    "                s_mae = extract(prefix, 'Support_MAE', logs)\n",
    "                s_mape = extract(prefix, 'Support_MAPE', logs)\n",
    "                q_mse = extract(prefix, 'Query_MSE', logs)\n",
    "                q_mae = extract(prefix, 'Query_MAE', logs)\n",
    "                q_mape = extract(prefix, 'Query_MAPE', logs)\n",
    "\n",
    "                print(f'[Meta {prefix}]({step+1}/{total_steps})')\n",
    "                print(f'  - [Support] MSE: {s_mse}, MAE: {s_mae}, MAPE: {s_mape}')\n",
    "                print(f'  - [Query] MSE: {q_mse}, MAE: {q_mae}, MAPE: {q_mape}')\n",
    "                print()\n",
    "                \n",
    "    def get_best_results(self, exp_num, record_tensorboard: bool=True):\n",
    "        self.init_experiments(exp_num=exp_num, record_tensorboard=record_tensorboard)\n",
    "        best_ckpt = sorted(\n",
    "            (self.ckpt_step_valid_path).glob('*.ckpt'),\n",
    "            key=lambda x: x.name.split('-')[1], \n",
    "            reverse=True\n",
    "        )[0]\n",
    "        \n",
    "        best_step, train_loss = best_ckpt.name.rstrip('.ckpt').split('-')\n",
    "        state_dict = torch.load(best_ckpt)\n",
    "        return int(best_step), float(train_loss), state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa6ab8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test_mix.all_tasks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e6a1e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionMetricRecorder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        cs = tm.MetricCollection({\n",
    "            'Support_MSE': tm.MeanMetric(), \n",
    "            'Support_MAE': tm.MeanMetric(),\n",
    "            'Support_MAPE': tm.MeanMetric(),\n",
    "            'Query_MSE': tm.MeanMetric(), \n",
    "            'Query_MAE': tm.MeanMetric(),\n",
    "            'Query_MAPE': tm.MeanMetric(),\n",
    "        })\n",
    "\n",
    "        self.metrics = cs.clone()\n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self.metrics.keys())\n",
    "    \n",
    "    def update(self, key, scores):\n",
    "        self.metrics[key].update(scores)\n",
    "            \n",
    "    def compute(self, prefix: str):\n",
    "        results = {}\n",
    "        for k in self.keys:\n",
    "            m = self.metrics[k].compute()\n",
    "            if isinstance(m, torch.Tensor):\n",
    "                m = m.cpu().detach().numpy()\n",
    "            results[f'{prefix}-{k}'] = m\n",
    "        return results\n",
    "    \n",
    "    def reset(self):\n",
    "        for k in self.keys:\n",
    "            self.metrics[k].reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "11aed9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionMetricTaskRecorder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        cs = tm.MetricCollection({\n",
    "            'Support_MSE': tm.MeanSquaredError(), \n",
    "            'Support_MAE': tm.MeanAbsoluteError(),\n",
    "            'Support_MAPE': tm.MeanAbsolutePercentageError(),\n",
    "            'Query_MSE': tm.MeanSquaredError(), \n",
    "            'Query_MAE': tm.MeanAbsoluteError(),\n",
    "            'Query_MAPE': tm.MeanAbsolutePercentageError(),\n",
    "        })\n",
    "        \n",
    "        self.metrics = cs.clone()\n",
    "        \n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self.metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a9b16166",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'kdd17_0'\n",
    "log_dir = './logging'\n",
    "task_type = \"regression\"\n",
    "model = PanelRegressionModel(feature_size=11, embed_size=32, output_size=1, num_layers=1, drop_rate=0, device='cuda')\n",
    "batch_size = 64\n",
    "n_inner_step = 2\n",
    "total_steps = 2\n",
    "n_valid_step = 2\n",
    "every_valid_step = 2\n",
    "print_step = 1\n",
    "inner_lr = 0.01\n",
    "outer_lr = 0.001\n",
    "device = 'cuda'\n",
    "clip_value = 0\n",
    "test_window_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d813647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_train = Maml_Regression_Trainer(exp_name,log_dir, task_type, model, batch_size, n_inner_step, total_steps, n_valid_step, every_valid_step, print_step, inner_lr, outer_lr, device, clip_value, test_window_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "099a7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_train.init_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bda8ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Train](1/2)\n",
      "  - [Support] MSE: 2.9967, MAE: 1.1789, MAPE: 3500.3667\n",
      "  - [Query] MSE: 2.2061, MAE: 1.0476, MAPE: 1.0913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-time: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-time](1/2)\n",
      "  - [Support] MSE: 2.1760, MAE: 1.0574, MAPE: 1795.5468\n",
      "  - [Query] MSE: 3.0426, MAE: 1.2335, MAPE: 1.2080\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-entity: 100%|█████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-entity](1/2)\n",
      "  - [Support] MSE: 4.1395, MAE: 1.2132, MAPE: 1.0871\n",
      "  - [Query] MSE: 3.8890, MAE: 1.2704, MAPE: 1.0731\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-mix: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-mix](1/2)\n",
      "  - [Support] MSE: 3.1395, MAE: 1.1972, MAPE: 1.1013\n",
      "  - [Query] MSE: 3.6928, MAE: 1.2906, MAPE: 1.0104\n",
      "\n",
      "[Meta Valid] Result - AvgMSE: 3.5415, AvgMAE: 1.2648, AvgMAPE: 1.0972 \n",
      "\n",
      "[Meta Train](2/2)\n",
      "  - [Support] MSE: 5.5980, MAE: 1.3855, MAPE: 1.0214\n",
      "  - [Query] MSE: 5.4727, MAE: 1.3126, MAPE: 1.0275\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-time: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-time](2/2)\n",
      "  - [Support] MSE: 2.1751, MAE: 1.0351, MAPE: 26.6098\n",
      "  - [Query] MSE: 1.8135, MAE: 1.0152, MAPE: 1.4320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-entity: 100%|█████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-entity](2/2)\n",
      "  - [Support] MSE: 3.1640, MAE: 1.2556, MAPE: 1.2167\n",
      "  - [Query] MSE: 5.8260, MAE: 1.4548, MAPE: 1.1026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-mix: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-mix](2/2)\n",
      "  - [Support] MSE: 2.9875, MAE: 1.1575, MAPE: 415.5214\n",
      "  - [Query] MSE: 2.2653, MAE: 1.1087, MAPE: 1.2722\n",
      "\n",
      "[Meta Valid] Result - AvgMSE: 3.3016, AvgMAE: 1.1929, AvgMAPE: 1.2689 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "maml_train.meta_train(meta_train, meta_valid_time, meta_valid_entity, meta_valid_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aefedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "maml_train.meta_test(maml_train.model, meta_test_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d904af1",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f5ab5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2160fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data for train: 100%|██████████| 35/35 [00:01<00:00, 18.51it/s]\n",
      "Processing data for valid-time: 100%|██████████| 35/35 [00:01<00:00, 20.25it/s]\n",
      "Processing data for valid-stock: 100%|██████████| 10/10 [00:00<00:00, 34.79it/s]\n",
      "Processing data for valid-mix: 100%|██████████| 10/10 [00:00<00:00, 34.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Train](1/2)\n",
      "  - [Support] MSE: 3.3771, MAE: 1.1968, MAPE: 1376.7026\n",
      "  - [Query] MSE: 5.2867, MAE: 1.3220, MAPE: 1.2026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-time: 100%|██████████| 2/2 [00:01<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-time](1/2)\n",
      "  - [Support] MSE: 2.0565, MAE: 1.0411, MAPE: 1.4727\n",
      "  - [Query] MSE: 1.7249, MAE: 0.9458, MAPE: 1.2283\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-entity: 100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-entity](1/2)\n",
      "  - [Support] MSE: 6.3472, MAE: 1.4712, MAPE: 5279.9619\n",
      "  - [Query] MSE: 3.5692, MAE: 1.3363, MAPE: 1.5096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-mix: 100%|██████████| 2/2 [00:01<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-mix](1/2)\n",
      "  - [Support] MSE: 2.3849, MAE: 1.1043, MAPE: 1308.6726\n",
      "  - [Query] MSE: 3.1623, MAE: 1.1943, MAPE: 2937.7285\n",
      "\n",
      "[Meta Valid] Result - AvgMSE: 2.8188, AvgMAE: 1.1588, AvgMAPE: 980.1554 \n",
      "\n",
      "[Meta Train](2/2)\n",
      "  - [Support] MSE: 3.3169, MAE: 1.1227, MAPE: 1107.1417\n",
      "  - [Query] MSE: 2.7269, MAE: 1.1582, MAPE: 1.0413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-time: 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-time](2/2)\n",
      "  - [Support] MSE: 2.5666, MAE: 1.1671, MAPE: 6206.4971\n",
      "  - [Query] MSE: 2.2045, MAE: 1.0625, MAPE: 1.0509\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-entity: 100%|██████████| 2/2 [00:01<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-entity](2/2)\n",
      "  - [Support] MSE: 3.9120, MAE: 1.3579, MAPE: 1912.7567\n",
      "  - [Query] MSE: 3.3036, MAE: 1.2139, MAPE: 19067.9121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Valid-mix: 100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Valid-mix](2/2)\n",
      "  - [Support] MSE: 2.7863, MAE: 1.1711, MAPE: 1075.2561\n",
      "  - [Query] MSE: 2.4320, MAE: 1.1463, MAPE: 1.7128\n",
      "\n",
      "[Meta Valid] Result - AvgMSE: 2.6467, AvgMAE: 1.1409, AvgMAPE: 6356.8919 \n",
      "\n",
      "====================\n",
      "[Meta Train Query Result] Best Step: 0 | Loss: 2.8188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data for test-time: 100%|██████████| 35/35 [00:02<00:00, 16.11it/s]\n",
      "Processing data for test-stock: 100%|██████████| 5/5 [00:00<00:00, 11.32it/s]\n",
      "Processing data for test-mix: 100%|██████████| 5/5 [00:00<00:00, 14.66it/s]\n",
      "Running Test-time: 100%|██████████| 8120/8120 [01:53<00:00, 71.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Test-time](1/0)\n",
      "  - [Support] MSE: 2.2693, MAE: 0.9830, MAPE: 801.0791\n",
      "  - [Query] MSE: 2.4107, MAE: 1.0000, MAPE: 876.0533\n",
      "\n",
      "[Meta Test-time] MSE: 2.4107 | MAE: 1.0000 | MAPE: 876.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Test-stock: 100%|██████████| 9825/9825 [02:16<00:00, 72.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Test-stock](1/0)\n",
      "  - [Support] MSE: 4.8112, MAE: 1.2883, MAPE: 603.0672\n",
      "  - [Query] MSE: 5.0157, MAE: 1.3260, MAPE: 739.4522\n",
      "\n",
      "[Meta Test-stock] MSE: 5.0157 | MAE: 1.3260 | MAPE: 739.4522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Test-mix: 100%|██████████| 1160/1160 [00:16<00:00, 70.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta Test-mix](1/0)\n",
      "  - [Support] MSE: 2.5169, MAE: 1.0679, MAPE: 231.7329\n",
      "  - [Query] MSE: 2.6519, MAE: 1.0834, MAPE: 27.9170\n",
      "\n",
      "[Meta Test-mix] MSE: 2.6519 | MAE: 1.0834 | MAPE: 27.9170\n",
      "[Meta Test] AvgMSE: 3.3594 | AvgMAE: 1.1365 | AvgMAPE:  547.8076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "    if not args.meta_test:\n",
    "        setting_file = args.exp\n",
    "        if '.yml' not in args.exp:\n",
    "            setting_file += '.yml'\n",
    "        setting_file = Path(args.exp_dir) / setting_file\n",
    "        meta_args = ARGProcessor(setting_file=setting_file)\n",
    "        data_kwargs = meta_args.get_args(cls=StockRegressionDataset)\n",
    "\n",
    "        meta_train = StockRegressionDataset(meta_type='train', **data_kwargs)\n",
    "        meta_valid_time = StockRegressionDataset(meta_type='valid-time', **data_kwargs)\n",
    "        meta_valid_entity = StockRegressionDataset(meta_type='valid-stock',**data_kwargs)\n",
    "        meta_valid_mix = StockRegressionDataset(meta_type='valid-mix', **data_kwargs)\n",
    "        meta_train.generate_all_task()\n",
    "        meta_valid_time.generate_all_task()\n",
    "        meta_valid_entity.generate_all_task()\n",
    "        meta_valid_mix.generate_all_task()\n",
    "        \n",
    "        model_kwargs = meta_args.get_args(cls=PanelRegressionModel)\n",
    "        model = PanelRegressionModel(**model_kwargs)\n",
    "\n",
    "        trainer_kwargs = meta_args.get_args(cls=Maml_Regression_Trainer)\n",
    "        trainer = Maml_Regression_Trainer(**trainer_kwargs, model=model)\n",
    "\n",
    "        # meta train\n",
    "        trainer.init_experiments(exp_num=None, record_tensorboard=True)\n",
    "        meta_args.save(trainer.exp_dir / 'settings.yml')\n",
    "        trainer.meta_train(\n",
    "            meta_trainset=meta_train,\n",
    "            meta_validset_time=meta_valid_time,\n",
    "            meta_validset_entity=meta_valid_entity,\n",
    "            meta_validset_mix=meta_valid_mix, \n",
    "            print_log=True\n",
    "        )\n",
    "        \n",
    "\n",
    "        # meta test \n",
    "        print('=='*10)\n",
    "        best_step, train_loss, state_dict = trainer.get_best_results(\n",
    "            exp_num=trainer.exp_num, record_tensorboard=True\n",
    "        )\n",
    "        model = PanelRegressionModel(**model_kwargs)\n",
    "        model.load_state_dict(state_dict=state_dict)\n",
    "\n",
    "        print(f'[Meta Train Query Result] Best Step: {best_step} | Loss: {train_loss:.4f}')\n",
    "        meta_test_time = StockRegressionDataset(meta_type='test-time', **data_kwargs)\n",
    "        meta_test_entity = StockRegressionDataset(meta_type='test-stock', **data_kwargs)\n",
    "        meta_test_mix = StockRegressionDataset(meta_type='test-mix', **data_kwargs)\n",
    "        \n",
    "        meta_test_time.generate_all_task()\n",
    "        meta_test_entity.generate_all_task()\n",
    "        meta_test_mix.generate_all_task()\n",
    "        \n",
    "        test_mses = []\n",
    "        test_maes = []\n",
    "        test_mapes = []\n",
    "        for meta_test in [meta_test_time, meta_test_entity, meta_test_mix]:\n",
    "            prefix, eval_mse, eval_mae, eval_mape = trainer.meta_test(\n",
    "                model=model, \n",
    "                meta_dataset=meta_test\n",
    "                \n",
    "            )\n",
    "    \n",
    "            print(f'[Meta {prefix}] MSE: {eval_mse:.4f} | MAE: {eval_mae:.4f} | MAPE: {eval_mape:.4f}')\n",
    "            test_mses.append(eval_mse)\n",
    "            test_maes.append(eval_mae)\n",
    "            test_mapes.append(eval_mape)\n",
    "            \n",
    "        avgmse = np.array(test_mses).mean()\n",
    "        avgmae = np.array(test_maes).mean()\n",
    "        avgmape = np.array(test_mapes).mean()\n",
    "        \n",
    "        print(f'[Meta Test] AvgMSE: {avgmse:.4f} | AvgMAE: {avgmae:.4f} | AvgMAPE: {avgmape: .4f}')\n",
    "\n",
    "    else:\n",
    "        record_file = open(f'./all_results.csv', 'w', encoding='utf-8')\n",
    "        # record_file_win = open(f'./all_results_win.csv', 'w', encoding='utf-8')\n",
    "        print('Experiment,TestType,TestMSE,TestMAE,TestMAPE', file=record_file) \n",
    "        # print('Experiment,TestType,WindowSize,TestLoss,TestLossStd,TestAccuracy,TestAccuracyStd,TrainAccuracy,TrainLoss', file=record_file_win) \n",
    "        \n",
    "        all_exps = {}\n",
    "        for p in Path('./logging').glob('*'):\n",
    "            if p.is_dir():\n",
    "                e_name = '_'.join(p.name.split('_')[:-1])\n",
    "                e_num = int(p.name.split('_')[-1])\n",
    "                if all_exps.get(e_name) is None:\n",
    "                    all_exps[e_name] = (p, e_num)\n",
    "                else:\n",
    "                    all_exps[e_name] = (p, max(e_num, all_exps[e_name][1]))\n",
    "\n",
    "        all_exps = list(all_exps.values())\n",
    "\n",
    "        for exp, exp_num in all_exps:\n",
    "            ename = '_'.join(exp.name.split(\"_\")[:-1])\n",
    "            print(f'Processing: {ename}')\n",
    "            setting_file = exp / 'settings.yml'\n",
    "        \n",
    "            meta_args = ARGProcessor(setting_file=setting_file)\n",
    "            data_kwargs = meta_args.get_args(cls=StockRegressionDataset)\n",
    "\n",
    "            # only meta test for all/specific experiments\n",
    "            meta_test_time = StockRegressionDataset(meta_type='test-time', **data_kwargs)\n",
    "            meta_test_entity = StockRegressionDataset(meta_type='test-stock', **data_kwargs)\n",
    "            meta_test_mix = StockRegressionDataset(meta_type='test-mix', **data_kwargs)\n",
    "            meta_test_time.generate_all_task()\n",
    "            meta_test_entity.generate_all_task()\n",
    "            meta_test_mix.generate_all_task()\n",
    "            \n",
    "            model_kwargs = meta_args.get_args(cls=PanelRegressionModel)\n",
    "            model = PanelRegressionModel(**model_kwargs)\n",
    "            trainer_kwargs = meta_args.get_args(cls=Maml_Regression_Trainer)\n",
    "            trainer = Maml_Regression_Trainer(**trainer_kwargs, model=model)\n",
    "            \n",
    "            best_step, train_loss, state_dict = trainer.get_best_results(\n",
    "                exp_num=exp_num, record_tensorboard=False)  # get best results and state dict\n",
    "            \n",
    "            \n",
    "            model.load_state_dict(state_dict=state_dict)\n",
    "\n",
    "            print(f'[Meta Valid Query Result] Best Step: {best_step} | Loss: {train_loss:.4f}')\n",
    "\n",
    "            for meta_test in [meta_test_time, meta_test_entity, meta_test_mix]:\n",
    "                prefix, eval_mse, eval_mae, eval_mape = trainer.meta_test(\n",
    "                model=model, \n",
    "                meta_dataset=meta_test\n",
    "                )\n",
    "                print(f'[Meta {prefix}] MSE: {eval_mse:.4f} | MAE: {eval_mae:.4f} | MAPE: {eval_mape:.4f}')\n",
    "                # 'Experiment,TestType,TestLoss,TestLossStd,TestAccuracy,TestAccuracyStd,TrainAccuracy,TrainLoss'\n",
    "                print(\n",
    "                    f'{ename},{prefix},{eval_mse:.4f},{eval_mae:.4f},{eval_mape:.4f}', \n",
    "                    file=record_file\n",
    "                )\n",
    "                # for win_size in meta_test.window_sizes:\n",
    "                #     # 'Experiment,TestType,WindowSize,TestLoss,TestLossStd,TestAccuracy,TestAccuracyStd,TrainAccuracy,TrainLoss'\n",
    "                #     test_acc, test_acc_std = test_win_acc_loss[f'{prefix}-WinSize={win_size}-Query_Accuracy']\n",
    "                #     test_loss, test_loss_std = test_win_acc_loss[f'{prefix}-WinSize={win_size}-Query_Loss']\n",
    "                #     print(\n",
    "                #         f'{ename},{prefix},{win_size},{test_loss:.4f},{test_loss_std:.4f},{test_acc:.4f},{test_acc_std:.4f},{train_acc:.4f},{train_loss:.4f}', \n",
    "                #         file=record_file_win\n",
    "                #     )\n",
    "        \n",
    "        record_file.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--exp_dir', default='./', type=str)\n",
    "    parser.add_argument('--exp', default='kdd', type=str)\n",
    "    parser.add_argument('--meta_test', action='store_true')\n",
    "    args = parser.parse_args(args=[])\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8172cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': array([[[[ 3.23363379,  3.31446645, -1.37429264, ..., 13.3367044 ,\n",
       "           15.01374566, 17.9237435 ],\n",
       "          [ 2.70607827,  2.70607827, -2.20649459, ..., 15.79516569,\n",
       "           17.17401675, 20.1970533 ],\n",
       "          [ 4.24191954,  4.70391032, -0.37799246, ..., 15.90508272,\n",
       "           16.99790088, 19.95940182],\n",
       "          ...,\n",
       "          [ 2.94358557,  3.02535581, -1.0629518 , ...,  3.0273959 ,\n",
       "            6.38103448,  7.68602185],\n",
       "          [-2.83975254,  0.20284381, -3.0020284 , ...,  1.33266068,\n",
       "            4.97525695,  6.37863729],\n",
       "          [-1.67346939,  0.65306122, -3.06122449, ...,  1.01020344,\n",
       "            4.74285642,  6.42312838]]],\n",
       " \n",
       " \n",
       "        [[[ 2.70607827,  2.70607827, -2.20649459, ..., 15.79516569,\n",
       "           17.17401675, 20.1970533 ],\n",
       "          [ 4.24191954,  4.70391032, -0.37799246, ..., 15.90508272,\n",
       "           16.99790088, 19.95940182],\n",
       "          [-1.54762692,  0.71427775, -3.49206732, ...,  8.92063173,\n",
       "           10.02063184, 12.25793318],\n",
       "          ...,\n",
       "          [-2.83975254,  0.20284381, -3.0020284 , ...,  1.33266068,\n",
       "            4.97525695,  6.37863729],\n",
       "          [-1.67346939,  0.65306122, -3.06122449, ...,  1.01020344,\n",
       "            4.74285642,  6.42312838],\n",
       "          [-0.7311828 ,  0.38709677, -1.59140215, ...,  5.33118119,\n",
       "            9.26107353, 11.53261444]]],\n",
       " \n",
       " \n",
       "        [[[ 4.24191954,  4.70391032, -0.37799246, ..., 15.90508272,\n",
       "           16.99790088, 19.95940182],\n",
       "          [-1.54762692,  0.71427775, -3.49206732, ...,  8.92063173,\n",
       "           10.02063184, 12.25793318],\n",
       "          [-0.46571124,  1.18543179, -1.65114726, ..., 15.0762033 ,\n",
       "           16.3996578 , 18.51679007],\n",
       "          ...,\n",
       "          [-1.67346939,  0.65306122, -3.06122449, ...,  1.01020344,\n",
       "            4.74285642,  6.42312838],\n",
       "          [-0.7311828 ,  0.38709677, -1.59140215, ...,  5.33118119,\n",
       "            9.26107353, 11.53261444],\n",
       "          [-2.2754452 ,  0.07984431, -5.10977665, ..., -2.95608561,\n",
       "            0.7153716 ,  3.20825233]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[-0.41699562,  0.51627878, -1.1914277 , ..., -3.0232344 ,\n",
       "           -3.67275803, -3.82049422],\n",
       "          [-1.28454649,  0.09731218, -1.8295095 , ..., -4.58544332,\n",
       "           -5.29544721, -5.50019613],\n",
       "          [ 0.19557793,  0.29336592, -0.29337179, ..., -3.79914176,\n",
       "           -4.50459827, -4.80996382],\n",
       "          ...,\n",
       "          [-1.49115372,  0.16775395, -1.73345939, ..., -4.10811043,\n",
       "           -5.09897704, -6.32370551],\n",
       "          [-0.05588301,  0.13040238, -0.44709575, ..., -3.881333  ,\n",
       "           -4.71683983, -5.94200147],\n",
       "          [ 0.09321402,  0.35421887, -0.37285608, ..., -3.57475644,\n",
       "           -4.23042408, -5.43996933]]],\n",
       " \n",
       " \n",
       "        [[[-1.28454649,  0.09731218, -1.8295095 , ..., -4.58544332,\n",
       "           -5.29544721, -5.50019613],\n",
       "          [ 0.19557793,  0.29336592, -0.29337179, ..., -3.79914176,\n",
       "           -4.50459827, -4.80996382],\n",
       "          [-0.77685373,  0.2718955 , -1.1070188 , ..., -4.00563453,\n",
       "           -4.81336408, -5.28452389],\n",
       "          ...,\n",
       "          [-0.05588301,  0.13040238, -0.44709575, ..., -3.881333  ,\n",
       "           -4.71683983, -5.94200147],\n",
       "          [ 0.09321402,  0.35421887, -0.37285608, ..., -3.57475644,\n",
       "           -4.23042408, -5.43996933],\n",
       "          [ 0.35554267,  0.72979605, -0.13098803, ..., -2.9818446 ,\n",
       "           -3.48802017, -4.63322983]]],\n",
       " \n",
       " \n",
       "        [[[ 0.19557793,  0.29336592, -0.29337179, ..., -3.79914176,\n",
       "           -4.50459827, -4.80996382],\n",
       "          [-0.77685373,  0.2718955 , -1.1070188 , ..., -4.00563453,\n",
       "           -4.81336408, -5.28452389],\n",
       "          [-0.42503286,  1.29443977, -0.54095443, ..., -4.01661215,\n",
       "           -4.94821979, -5.54997165],\n",
       "          ...,\n",
       "          [ 0.09321402,  0.35421887, -0.37285608, ..., -3.57475644,\n",
       "           -4.23042408, -5.43996933],\n",
       "          [ 0.35554267,  0.72979605, -0.13098803, ..., -2.9818446 ,\n",
       "           -3.48802017, -4.63322983],\n",
       "          [-0.27912541,  0.2977298 , -0.42799403, ..., -3.16617267,\n",
       "           -3.71046035, -4.77050234]]]]),\n",
       " 'query_labels': array([[-5.10204082],\n",
       "        [ 7.74193118],\n",
       "        [ 7.6247508 ],\n",
       "        ...,\n",
       "        [-0.37285608],\n",
       "        [ 0.56138287],\n",
       "        [-0.66989391]]),\n",
       " 'support': array([[[[-5.98380852e-01,  5.98380852e-01, -2.25272791e+00, ...,\n",
       "            2.08729423e+00,  4.74199379e+00,  7.44808354e+00],\n",
       "          [ 8.02788831e-01,  9.42408377e-01, -1.43106457e+00, ...,\n",
       "            6.91099934e-01,  3.24188564e+00,  5.81500988e+00],\n",
       "          [-1.47987416e-01,  4.06947821e-01, -1.25786159e+00, ...,\n",
       "            5.98963766e+00,  8.53421782e+00,  1.12134635e+01],\n",
       "          ...,\n",
       "          [-2.72309163e+00,  8.79761170e-01, -3.60285280e+00, ...,\n",
       "            1.12211949e+01,  1.23837415e+01,  1.38304666e+01],\n",
       "          [ 3.07109802e+00,  3.70214556e+00, -1.34623054e+00, ...,\n",
       "            1.07446332e+01,  1.21144265e+01,  1.36460489e+01],\n",
       "          [ 1.48926851e+00,  2.10249233e+00, -5.25628559e-01, ...,\n",
       "            1.37647831e+01,  1.56565918e+01,  1.73645781e+01]],\n",
       " \n",
       "         [[ 8.02788831e-01,  9.42408377e-01, -1.43106457e+00, ...,\n",
       "            6.91099934e-01,  3.24188564e+00,  5.81500988e+00],\n",
       "          [-1.47987416e-01,  4.06947821e-01, -1.25786159e+00, ...,\n",
       "            5.98963766e+00,  8.53421782e+00,  1.12134635e+01],\n",
       "          [-1.93719496e-01,  2.05347160e+00, -4.26183666e-01, ...,\n",
       "            1.04784964e+01,  1.24881824e+01,  1.53842181e+01],\n",
       "          ...,\n",
       "          [ 3.07109802e+00,  3.70214556e+00, -1.34623054e+00, ...,\n",
       "            1.07446332e+01,  1.21144265e+01,  1.36460489e+01],\n",
       "          [ 1.48926851e+00,  2.10249233e+00, -5.25628559e-01, ...,\n",
       "            1.37647831e+01,  1.56565918e+01,  1.73645781e+01],\n",
       "          [-2.62402225e+00,  1.64005747e-01, -3.40303417e+00, ...,\n",
       "            5.39565855e+00,  7.74580178e+00,  9.10482866e+00]],\n",
       " \n",
       "         [[-1.47987416e-01,  4.06947821e-01, -1.25786159e+00, ...,\n",
       "            5.98963766e+00,  8.53421782e+00,  1.12134635e+01],\n",
       "          [-1.93719496e-01,  2.05347160e+00, -4.26183666e-01, ...,\n",
       "            1.04784964e+01,  1.24881824e+01,  1.53842181e+01],\n",
       "          [ 3.11128839e+00,  3.47028720e+00, -2.79218189e-01, ...,\n",
       "            1.28739547e+01,  1.46262483e+01,  1.75588373e+01],\n",
       "          ...,\n",
       "          [ 1.48926851e+00,  2.10249233e+00, -5.25628559e-01, ...,\n",
       "            1.37647831e+01,  1.56565918e+01,  1.73645781e+01],\n",
       "          [-2.62402225e+00,  1.64005747e-01, -3.40303417e+00, ...,\n",
       "            5.39565855e+00,  7.74580178e+00,  9.10482866e+00],\n",
       "          [-4.97925311e-01,  2.53111618e+00, -1.20332365e+00, ...,\n",
       "            5.56431638e+00,  8.49792599e+00,  9.80497956e+00]],\n",
       " \n",
       "         [[-1.93719496e-01,  2.05347160e+00, -4.26183666e-01, ...,\n",
       "            1.04784964e+01,  1.24881824e+01,  1.53842181e+01],\n",
       "          [ 3.11128839e+00,  3.47028720e+00, -2.79218189e-01, ...,\n",
       "            1.28739547e+01,  1.46262483e+01,  1.75588373e+01],\n",
       "          [ 3.23363379e+00,  3.31446645e+00, -1.37429264e+00, ...,\n",
       "            1.33367044e+01,  1.50137457e+01,  1.79237435e+01],\n",
       "          ...,\n",
       "          [-2.62402225e+00,  1.64005747e-01, -3.40303417e+00, ...,\n",
       "            5.39565855e+00,  7.74580178e+00,  9.10482866e+00],\n",
       "          [-4.97925311e-01,  2.53111618e+00, -1.20332365e+00, ...,\n",
       "            5.56431638e+00,  8.49792599e+00,  9.80497956e+00],\n",
       "          [ 2.94358557e+00,  3.02535581e+00, -1.06295180e+00, ...,\n",
       "            3.02739590e+00,  6.38103448e+00,  7.68602185e+00]],\n",
       " \n",
       "         [[ 3.11128839e+00,  3.47028720e+00, -2.79218189e-01, ...,\n",
       "            1.28739547e+01,  1.46262483e+01,  1.75588373e+01],\n",
       "          [ 3.23363379e+00,  3.31446645e+00, -1.37429264e+00, ...,\n",
       "            1.33367044e+01,  1.50137457e+01,  1.79237435e+01],\n",
       "          [ 2.70607827e+00,  2.70607827e+00, -2.20649459e+00, ...,\n",
       "            1.57951657e+01,  1.71740168e+01,  2.01970533e+01],\n",
       "          ...,\n",
       "          [-4.97925311e-01,  2.53111618e+00, -1.20332365e+00, ...,\n",
       "            5.56431638e+00,  8.49792599e+00,  9.80497956e+00],\n",
       "          [ 2.94358557e+00,  3.02535581e+00, -1.06295180e+00, ...,\n",
       "            3.02739590e+00,  6.38103448e+00,  7.68602185e+00],\n",
       "          [-2.83975254e+00,  2.02843813e-01, -3.00202840e+00, ...,\n",
       "            1.33266068e+00,  4.97525695e+00,  6.37863729e+00]]],\n",
       " \n",
       " \n",
       "        [[[ 8.02788831e-01,  9.42408377e-01, -1.43106457e+00, ...,\n",
       "            6.91099934e-01,  3.24188564e+00,  5.81500988e+00],\n",
       "          [-1.47987416e-01,  4.06947821e-01, -1.25786159e+00, ...,\n",
       "            5.98963766e+00,  8.53421782e+00,  1.12134635e+01],\n",
       "          [-1.93719496e-01,  2.05347160e+00, -4.26183666e-01, ...,\n",
       "            1.04784964e+01,  1.24881824e+01,  1.53842181e+01],\n",
       "          ...,\n",
       "          [ 3.07109802e+00,  3.70214556e+00, -1.34623054e+00, ...,\n",
       "            1.07446332e+01,  1.21144265e+01,  1.36460489e+01],\n",
       "          [ 1.48926851e+00,  2.10249233e+00, -5.25628559e-01, ...,\n",
       "            1.37647831e+01,  1.56565918e+01,  1.73645781e+01],\n",
       "          [-2.62402225e+00,  1.64005747e-01, -3.40303417e+00, ...,\n",
       "            5.39565855e+00,  7.74580178e+00,  9.10482866e+00]],\n",
       " \n",
       "         [[-1.47987416e-01,  4.06947821e-01, -1.25786159e+00, ...,\n",
       "            5.98963766e+00,  8.53421782e+00,  1.12134635e+01],\n",
       "          [-1.93719496e-01,  2.05347160e+00, -4.26183666e-01, ...,\n",
       "            1.04784964e+01,  1.24881824e+01,  1.53842181e+01],\n",
       "          [ 3.11128839e+00,  3.47028720e+00, -2.79218189e-01, ...,\n",
       "            1.28739547e+01,  1.46262483e+01,  1.75588373e+01],\n",
       "          ...,\n",
       "          [ 1.48926851e+00,  2.10249233e+00, -5.25628559e-01, ...,\n",
       "            1.37647831e+01,  1.56565918e+01,  1.73645781e+01],\n",
       "          [-2.62402225e+00,  1.64005747e-01, -3.40303417e+00, ...,\n",
       "            5.39565855e+00,  7.74580178e+00,  9.10482866e+00],\n",
       "          [-4.97925311e-01,  2.53111618e+00, -1.20332365e+00, ...,\n",
       "            5.56431638e+00,  8.49792599e+00,  9.80497956e+00]],\n",
       " \n",
       "         [[-1.93719496e-01,  2.05347160e+00, -4.26183666e-01, ...,\n",
       "            1.04784964e+01,  1.24881824e+01,  1.53842181e+01],\n",
       "          [ 3.11128839e+00,  3.47028720e+00, -2.79218189e-01, ...,\n",
       "            1.28739547e+01,  1.46262483e+01,  1.75588373e+01],\n",
       "          [ 3.23363379e+00,  3.31446645e+00, -1.37429264e+00, ...,\n",
       "            1.33367044e+01,  1.50137457e+01,  1.79237435e+01],\n",
       "          ...,\n",
       "          [-2.62402225e+00,  1.64005747e-01, -3.40303417e+00, ...,\n",
       "            5.39565855e+00,  7.74580178e+00,  9.10482866e+00],\n",
       "          [-4.97925311e-01,  2.53111618e+00, -1.20332365e+00, ...,\n",
       "            5.56431638e+00,  8.49792599e+00,  9.80497956e+00],\n",
       "          [ 2.94358557e+00,  3.02535581e+00, -1.06295180e+00, ...,\n",
       "            3.02739590e+00,  6.38103448e+00,  7.68602185e+00]],\n",
       " \n",
       "         [[ 3.11128839e+00,  3.47028720e+00, -2.79218189e-01, ...,\n",
       "            1.28739547e+01,  1.46262483e+01,  1.75588373e+01],\n",
       "          [ 3.23363379e+00,  3.31446645e+00, -1.37429264e+00, ...,\n",
       "            1.33367044e+01,  1.50137457e+01,  1.79237435e+01],\n",
       "          [ 2.70607827e+00,  2.70607827e+00, -2.20649459e+00, ...,\n",
       "            1.57951657e+01,  1.71740168e+01,  2.01970533e+01],\n",
       "          ...,\n",
       "          [-4.97925311e-01,  2.53111618e+00, -1.20332365e+00, ...,\n",
       "            5.56431638e+00,  8.49792599e+00,  9.80497956e+00],\n",
       "          [ 2.94358557e+00,  3.02535581e+00, -1.06295180e+00, ...,\n",
       "            3.02739590e+00,  6.38103448e+00,  7.68602185e+00],\n",
       "          [-2.83975254e+00,  2.02843813e-01, -3.00202840e+00, ...,\n",
       "            1.33266068e+00,  4.97525695e+00,  6.37863729e+00]],\n",
       " \n",
       "         [[ 3.23363379e+00,  3.31446645e+00, -1.37429264e+00, ...,\n",
       "            1.33367044e+01,  1.50137457e+01,  1.79237435e+01],\n",
       "          [ 2.70607827e+00,  2.70607827e+00, -2.20649459e+00, ...,\n",
       "            1.57951657e+01,  1.71740168e+01,  2.01970533e+01],\n",
       "          [ 4.24191954e+00,  4.70391032e+00, -3.77992456e-01, ...,\n",
       "            1.59050827e+01,  1.69979009e+01,  1.99594018e+01],\n",
       "          ...,\n",
       "          [ 2.94358557e+00,  3.02535581e+00, -1.06295180e+00, ...,\n",
       "            3.02739590e+00,  6.38103448e+00,  7.68602185e+00],\n",
       "          [-2.83975254e+00,  2.02843813e-01, -3.00202840e+00, ...,\n",
       "            1.33266068e+00,  4.97525695e+00,  6.37863729e+00],\n",
       "          [-1.67346939e+00,  6.53061224e-01, -3.06122449e+00, ...,\n",
       "            1.01020344e+00,  4.74285642e+00,  6.42312838e+00]]],\n",
       " \n",
       " \n",
       "        [[[-1.47987416e-01,  4.06947821e-01, -1.25786159e+00, ...,\n",
       "            5.98963766e+00,  8.53421782e+00,  1.12134635e+01],\n",
       "          [-1.93719496e-01,  2.05347160e+00, -4.26183666e-01, ...,\n",
       "            1.04784964e+01,  1.24881824e+01,  1.53842181e+01],\n",
       "          [ 3.11128839e+00,  3.47028720e+00, -2.79218189e-01, ...,\n",
       "            1.28739547e+01,  1.46262483e+01,  1.75588373e+01],\n",
       "          ...,\n",
       "          [ 1.48926851e+00,  2.10249233e+00, -5.25628559e-01, ...,\n",
       "            1.37647831e+01,  1.56565918e+01,  1.73645781e+01],\n",
       "          [-2.62402225e+00,  1.64005747e-01, -3.40303417e+00, ...,\n",
       "            5.39565855e+00,  7.74580178e+00,  9.10482866e+00],\n",
       "          [-4.97925311e-01,  2.53111618e+00, -1.20332365e+00, ...,\n",
       "            5.56431638e+00,  8.49792599e+00,  9.80497956e+00]],\n",
       " \n",
       "         [[-1.93719496e-01,  2.05347160e+00, -4.26183666e-01, ...,\n",
       "            1.04784964e+01,  1.24881824e+01,  1.53842181e+01],\n",
       "          [ 3.11128839e+00,  3.47028720e+00, -2.79218189e-01, ...,\n",
       "            1.28739547e+01,  1.46262483e+01,  1.75588373e+01],\n",
       "          [ 3.23363379e+00,  3.31446645e+00, -1.37429264e+00, ...,\n",
       "            1.33367044e+01,  1.50137457e+01,  1.79237435e+01],\n",
       "          ...,\n",
       "          [-2.62402225e+00,  1.64005747e-01, -3.40303417e+00, ...,\n",
       "            5.39565855e+00,  7.74580178e+00,  9.10482866e+00],\n",
       "          [-4.97925311e-01,  2.53111618e+00, -1.20332365e+00, ...,\n",
       "            5.56431638e+00,  8.49792599e+00,  9.80497956e+00],\n",
       "          [ 2.94358557e+00,  3.02535581e+00, -1.06295180e+00, ...,\n",
       "            3.02739590e+00,  6.38103448e+00,  7.68602185e+00]],\n",
       " \n",
       "         [[ 3.11128839e+00,  3.47028720e+00, -2.79218189e-01, ...,\n",
       "            1.28739547e+01,  1.46262483e+01,  1.75588373e+01],\n",
       "          [ 3.23363379e+00,  3.31446645e+00, -1.37429264e+00, ...,\n",
       "            1.33367044e+01,  1.50137457e+01,  1.79237435e+01],\n",
       "          [ 2.70607827e+00,  2.70607827e+00, -2.20649459e+00, ...,\n",
       "            1.57951657e+01,  1.71740168e+01,  2.01970533e+01],\n",
       "          ...,\n",
       "          [-4.97925311e-01,  2.53111618e+00, -1.20332365e+00, ...,\n",
       "            5.56431638e+00,  8.49792599e+00,  9.80497956e+00],\n",
       "          [ 2.94358557e+00,  3.02535581e+00, -1.06295180e+00, ...,\n",
       "            3.02739590e+00,  6.38103448e+00,  7.68602185e+00],\n",
       "          [-2.83975254e+00,  2.02843813e-01, -3.00202840e+00, ...,\n",
       "            1.33266068e+00,  4.97525695e+00,  6.37863729e+00]],\n",
       " \n",
       "         [[ 3.23363379e+00,  3.31446645e+00, -1.37429264e+00, ...,\n",
       "            1.33367044e+01,  1.50137457e+01,  1.79237435e+01],\n",
       "          [ 2.70607827e+00,  2.70607827e+00, -2.20649459e+00, ...,\n",
       "            1.57951657e+01,  1.71740168e+01,  2.01970533e+01],\n",
       "          [ 4.24191954e+00,  4.70391032e+00, -3.77992456e-01, ...,\n",
       "            1.59050827e+01,  1.69979009e+01,  1.99594018e+01],\n",
       "          ...,\n",
       "          [ 2.94358557e+00,  3.02535581e+00, -1.06295180e+00, ...,\n",
       "            3.02739590e+00,  6.38103448e+00,  7.68602185e+00],\n",
       "          [-2.83975254e+00,  2.02843813e-01, -3.00202840e+00, ...,\n",
       "            1.33266068e+00,  4.97525695e+00,  6.37863729e+00],\n",
       "          [-1.67346939e+00,  6.53061224e-01, -3.06122449e+00, ...,\n",
       "            1.01020344e+00,  4.74285642e+00,  6.42312838e+00]],\n",
       " \n",
       "         [[ 2.70607827e+00,  2.70607827e+00, -2.20649459e+00, ...,\n",
       "            1.57951657e+01,  1.71740168e+01,  2.01970533e+01],\n",
       "          [ 4.24191954e+00,  4.70391032e+00, -3.77992456e-01, ...,\n",
       "            1.59050827e+01,  1.69979009e+01,  1.99594018e+01],\n",
       "          [-1.54762692e+00,  7.14277749e-01, -3.49206732e+00, ...,\n",
       "            8.92063173e+00,  1.00206318e+01,  1.22579332e+01],\n",
       "          ...,\n",
       "          [-2.83975254e+00,  2.02843813e-01, -3.00202840e+00, ...,\n",
       "            1.33266068e+00,  4.97525695e+00,  6.37863729e+00],\n",
       "          [-1.67346939e+00,  6.53061224e-01, -3.06122449e+00, ...,\n",
       "            1.01020344e+00,  4.74285642e+00,  6.42312838e+00],\n",
       "          [-7.31182796e-01,  3.87096774e-01, -1.59140215e+00, ...,\n",
       "            5.33118119e+00,  9.26107353e+00,  1.15326144e+01]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 1.37362640e-01,  3.72847339e-01, -3.72839489e-01, ...,\n",
       "           -5.50725902e+00, -5.54238442e+00, -5.18118591e+00],\n",
       "          [ 1.30259915e+00,  1.66332258e+00,  0.00000000e+00, ...,\n",
       "           -3.27555500e+00, -3.37074532e+00, -3.19172048e+00],\n",
       "          [-1.40364952e-01,  2.40631647e-01, -1.12291560e+00, ...,\n",
       "           -2.92359874e+00, -3.13294314e+00, -3.16756636e+00],\n",
       "          ...,\n",
       "          [-8.49260744e-01,  6.17641370e-01, -1.08087433e+00, ...,\n",
       "           -2.72727486e+00, -4.04941382e+00, -4.79830389e+00],\n",
       "          [-4.01758179e-01,  1.91295198e-02, -7.84386838e-01, ...,\n",
       "           -3.15955645e+00, -4.46680749e+00, -5.29175483e+00],\n",
       "          [-8.12700813e-01,  4.15802306e-01, -1.54980155e+00, ...,\n",
       "           -3.87355755e+00, -5.15214400e+00, -6.07005512e+00]],\n",
       " \n",
       "         [[ 1.30259915e+00,  1.66332258e+00,  0.00000000e+00, ...,\n",
       "           -3.27555500e+00, -3.37074532e+00, -3.19172048e+00],\n",
       "          [-1.40364952e-01,  2.40631647e-01, -1.12291560e+00, ...,\n",
       "           -2.92359874e+00, -3.13294314e+00, -3.16756636e+00],\n",
       "          [ 3.81447493e-01,  1.02388876e+00, -4.21608102e-01, ...,\n",
       "           -2.51154742e+00, -2.91427817e+00, -3.00609347e+00],\n",
       "          ...,\n",
       "          [-4.01758179e-01,  1.91295198e-02, -7.84386838e-01, ...,\n",
       "           -3.15955645e+00, -4.46680749e+00, -5.29175483e+00],\n",
       "          [-8.12700813e-01,  4.15802306e-01, -1.54980155e+00, ...,\n",
       "           -3.87355755e+00, -5.15214400e+00, -6.07005512e+00],\n",
       "          [-3.57678847e-01,  6.40060253e-01, -3.57678847e-01, ...,\n",
       "           -3.80082620e+00, -5.00451603e+00, -6.08621793e+00]],\n",
       " \n",
       "         [[-1.40364952e-01,  2.40631647e-01, -1.12291560e+00, ...,\n",
       "           -2.92359874e+00, -3.13294314e+00, -3.16756636e+00],\n",
       "          [ 3.81447493e-01,  1.02388876e+00, -4.21608102e-01, ...,\n",
       "           -2.51154742e+00, -2.91427817e+00, -3.00609347e+00],\n",
       "          [-2.00964824e-02,  6.63320603e-01, -2.00964824e-02, ...,\n",
       "           -2.12562852e+00, -2.67336736e+00, -2.78525999e+00],\n",
       "          ...,\n",
       "          [-8.12700813e-01,  4.15802306e-01, -1.54980155e+00, ...,\n",
       "           -3.87355755e+00, -5.15214400e+00, -6.07005512e+00],\n",
       "          [-3.57678847e-01,  6.40060253e-01, -3.57678847e-01, ...,\n",
       "           -3.80082620e+00, -5.00451603e+00, -6.08621793e+00],\n",
       "          [ 2.26541434e-01,  8.68414180e-01,  0.00000000e+00, ...,\n",
       "           -3.19992655e+00, -4.31263164e+00, -5.48549704e+00]],\n",
       " \n",
       "         [[ 3.81447493e-01,  1.02388876e+00, -4.21608102e-01, ...,\n",
       "           -2.51154742e+00, -2.91427817e+00, -3.00609347e+00],\n",
       "          [-2.00964824e-02,  6.63320603e-01, -2.00964824e-02, ...,\n",
       "           -2.12562852e+00, -2.67336736e+00, -2.78525999e+00],\n",
       "          [-4.16995623e-01,  5.16278782e-01, -1.19142770e+00, ...,\n",
       "           -3.02323440e+00, -3.67275803e+00, -3.82049422e+00],\n",
       "          ...,\n",
       "          [-3.57678847e-01,  6.40060253e-01, -3.57678847e-01, ...,\n",
       "           -3.80082620e+00, -5.00451603e+00, -6.08621793e+00],\n",
       "          [ 2.26541434e-01,  8.68414180e-01,  0.00000000e+00, ...,\n",
       "           -3.19992655e+00, -4.31263164e+00, -5.48549704e+00],\n",
       "          [-1.49115372e+00,  1.67753955e-01, -1.73345939e+00, ...,\n",
       "           -4.10811043e+00, -5.09897704e+00, -6.32370551e+00]],\n",
       " \n",
       "         [[-2.00964824e-02,  6.63320603e-01, -2.00964824e-02, ...,\n",
       "           -2.12562852e+00, -2.67336736e+00, -2.78525999e+00],\n",
       "          [-4.16995623e-01,  5.16278782e-01, -1.19142770e+00, ...,\n",
       "           -3.02323440e+00, -3.67275803e+00, -3.82049422e+00],\n",
       "          [-1.28454649e+00,  9.73121818e-02, -1.82950950e+00, ...,\n",
       "           -4.58544332e+00, -5.29544721e+00, -5.50019613e+00],\n",
       "          ...,\n",
       "          [ 2.26541434e-01,  8.68414180e-01,  0.00000000e+00, ...,\n",
       "           -3.19992655e+00, -4.31263164e+00, -5.48549704e+00],\n",
       "          [-1.49115372e+00,  1.67753955e-01, -1.73345939e+00, ...,\n",
       "           -4.10811043e+00, -5.09897704e+00, -6.32370551e+00],\n",
       "          [-5.58830104e-02,  1.30402385e-01, -4.47095753e-01, ...,\n",
       "           -3.88133300e+00, -4.71683983e+00, -5.94200147e+00]]],\n",
       " \n",
       " \n",
       "        [[[ 1.30259915e+00,  1.66332258e+00,  0.00000000e+00, ...,\n",
       "           -3.27555500e+00, -3.37074532e+00, -3.19172048e+00],\n",
       "          [-1.40364952e-01,  2.40631647e-01, -1.12291560e+00, ...,\n",
       "           -2.92359874e+00, -3.13294314e+00, -3.16756636e+00],\n",
       "          [ 3.81447493e-01,  1.02388876e+00, -4.21608102e-01, ...,\n",
       "           -2.51154742e+00, -2.91427817e+00, -3.00609347e+00],\n",
       "          ...,\n",
       "          [-4.01758179e-01,  1.91295198e-02, -7.84386838e-01, ...,\n",
       "           -3.15955645e+00, -4.46680749e+00, -5.29175483e+00],\n",
       "          [-8.12700813e-01,  4.15802306e-01, -1.54980155e+00, ...,\n",
       "           -3.87355755e+00, -5.15214400e+00, -6.07005512e+00],\n",
       "          [-3.57678847e-01,  6.40060253e-01, -3.57678847e-01, ...,\n",
       "           -3.80082620e+00, -5.00451603e+00, -6.08621793e+00]],\n",
       " \n",
       "         [[-1.40364952e-01,  2.40631647e-01, -1.12291560e+00, ...,\n",
       "           -2.92359874e+00, -3.13294314e+00, -3.16756636e+00],\n",
       "          [ 3.81447493e-01,  1.02388876e+00, -4.21608102e-01, ...,\n",
       "           -2.51154742e+00, -2.91427817e+00, -3.00609347e+00],\n",
       "          [-2.00964824e-02,  6.63320603e-01, -2.00964824e-02, ...,\n",
       "           -2.12562852e+00, -2.67336736e+00, -2.78525999e+00],\n",
       "          ...,\n",
       "          [-8.12700813e-01,  4.15802306e-01, -1.54980155e+00, ...,\n",
       "           -3.87355755e+00, -5.15214400e+00, -6.07005512e+00],\n",
       "          [-3.57678847e-01,  6.40060253e-01, -3.57678847e-01, ...,\n",
       "           -3.80082620e+00, -5.00451603e+00, -6.08621793e+00],\n",
       "          [ 2.26541434e-01,  8.68414180e-01,  0.00000000e+00, ...,\n",
       "           -3.19992655e+00, -4.31263164e+00, -5.48549704e+00]],\n",
       " \n",
       "         [[ 3.81447493e-01,  1.02388876e+00, -4.21608102e-01, ...,\n",
       "           -2.51154742e+00, -2.91427817e+00, -3.00609347e+00],\n",
       "          [-2.00964824e-02,  6.63320603e-01, -2.00964824e-02, ...,\n",
       "           -2.12562852e+00, -2.67336736e+00, -2.78525999e+00],\n",
       "          [-4.16995623e-01,  5.16278782e-01, -1.19142770e+00, ...,\n",
       "           -3.02323440e+00, -3.67275803e+00, -3.82049422e+00],\n",
       "          ...,\n",
       "          [-3.57678847e-01,  6.40060253e-01, -3.57678847e-01, ...,\n",
       "           -3.80082620e+00, -5.00451603e+00, -6.08621793e+00],\n",
       "          [ 2.26541434e-01,  8.68414180e-01,  0.00000000e+00, ...,\n",
       "           -3.19992655e+00, -4.31263164e+00, -5.48549704e+00],\n",
       "          [-1.49115372e+00,  1.67753955e-01, -1.73345939e+00, ...,\n",
       "           -4.10811043e+00, -5.09897704e+00, -6.32370551e+00]],\n",
       " \n",
       "         [[-2.00964824e-02,  6.63320603e-01, -2.00964824e-02, ...,\n",
       "           -2.12562852e+00, -2.67336736e+00, -2.78525999e+00],\n",
       "          [-4.16995623e-01,  5.16278782e-01, -1.19142770e+00, ...,\n",
       "           -3.02323440e+00, -3.67275803e+00, -3.82049422e+00],\n",
       "          [-1.28454649e+00,  9.73121818e-02, -1.82950950e+00, ...,\n",
       "           -4.58544332e+00, -5.29544721e+00, -5.50019613e+00],\n",
       "          ...,\n",
       "          [ 2.26541434e-01,  8.68414180e-01,  0.00000000e+00, ...,\n",
       "           -3.19992655e+00, -4.31263164e+00, -5.48549704e+00],\n",
       "          [-1.49115372e+00,  1.67753955e-01, -1.73345939e+00, ...,\n",
       "           -4.10811043e+00, -5.09897704e+00, -6.32370551e+00],\n",
       "          [-5.58830104e-02,  1.30402385e-01, -4.47095753e-01, ...,\n",
       "           -3.88133300e+00, -4.71683983e+00, -5.94200147e+00]],\n",
       " \n",
       "         [[-4.16995623e-01,  5.16278782e-01, -1.19142770e+00, ...,\n",
       "           -3.02323440e+00, -3.67275803e+00, -3.82049422e+00],\n",
       "          [-1.28454649e+00,  9.73121818e-02, -1.82950950e+00, ...,\n",
       "           -4.58544332e+00, -5.29544721e+00, -5.50019613e+00],\n",
       "          [ 1.95577935e-01,  2.93365924e-01, -2.93371792e-01, ...,\n",
       "           -3.79914176e+00, -4.50459827e+00, -4.80996382e+00],\n",
       "          ...,\n",
       "          [-1.49115372e+00,  1.67753955e-01, -1.73345939e+00, ...,\n",
       "           -4.10811043e+00, -5.09897704e+00, -6.32370551e+00],\n",
       "          [-5.58830104e-02,  1.30402385e-01, -4.47095753e-01, ...,\n",
       "           -3.88133300e+00, -4.71683983e+00, -5.94200147e+00],\n",
       "          [ 9.32140211e-02,  3.54218873e-01, -3.72856085e-01, ...,\n",
       "           -3.57475644e+00, -4.23042408e+00, -5.43996933e+00]]],\n",
       " \n",
       " \n",
       "        [[[-1.40364952e-01,  2.40631647e-01, -1.12291560e+00, ...,\n",
       "           -2.92359874e+00, -3.13294314e+00, -3.16756636e+00],\n",
       "          [ 3.81447493e-01,  1.02388876e+00, -4.21608102e-01, ...,\n",
       "           -2.51154742e+00, -2.91427817e+00, -3.00609347e+00],\n",
       "          [-2.00964824e-02,  6.63320603e-01, -2.00964824e-02, ...,\n",
       "           -2.12562852e+00, -2.67336736e+00, -2.78525999e+00],\n",
       "          ...,\n",
       "          [-8.12700813e-01,  4.15802306e-01, -1.54980155e+00, ...,\n",
       "           -3.87355755e+00, -5.15214400e+00, -6.07005512e+00],\n",
       "          [-3.57678847e-01,  6.40060253e-01, -3.57678847e-01, ...,\n",
       "           -3.80082620e+00, -5.00451603e+00, -6.08621793e+00],\n",
       "          [ 2.26541434e-01,  8.68414180e-01,  0.00000000e+00, ...,\n",
       "           -3.19992655e+00, -4.31263164e+00, -5.48549704e+00]],\n",
       " \n",
       "         [[ 3.81447493e-01,  1.02388876e+00, -4.21608102e-01, ...,\n",
       "           -2.51154742e+00, -2.91427817e+00, -3.00609347e+00],\n",
       "          [-2.00964824e-02,  6.63320603e-01, -2.00964824e-02, ...,\n",
       "           -2.12562852e+00, -2.67336736e+00, -2.78525999e+00],\n",
       "          [-4.16995623e-01,  5.16278782e-01, -1.19142770e+00, ...,\n",
       "           -3.02323440e+00, -3.67275803e+00, -3.82049422e+00],\n",
       "          ...,\n",
       "          [-3.57678847e-01,  6.40060253e-01, -3.57678847e-01, ...,\n",
       "           -3.80082620e+00, -5.00451603e+00, -6.08621793e+00],\n",
       "          [ 2.26541434e-01,  8.68414180e-01,  0.00000000e+00, ...,\n",
       "           -3.19992655e+00, -4.31263164e+00, -5.48549704e+00],\n",
       "          [-1.49115372e+00,  1.67753955e-01, -1.73345939e+00, ...,\n",
       "           -4.10811043e+00, -5.09897704e+00, -6.32370551e+00]],\n",
       " \n",
       "         [[-2.00964824e-02,  6.63320603e-01, -2.00964824e-02, ...,\n",
       "           -2.12562852e+00, -2.67336736e+00, -2.78525999e+00],\n",
       "          [-4.16995623e-01,  5.16278782e-01, -1.19142770e+00, ...,\n",
       "           -3.02323440e+00, -3.67275803e+00, -3.82049422e+00],\n",
       "          [-1.28454649e+00,  9.73121818e-02, -1.82950950e+00, ...,\n",
       "           -4.58544332e+00, -5.29544721e+00, -5.50019613e+00],\n",
       "          ...,\n",
       "          [ 2.26541434e-01,  8.68414180e-01,  0.00000000e+00, ...,\n",
       "           -3.19992655e+00, -4.31263164e+00, -5.48549704e+00],\n",
       "          [-1.49115372e+00,  1.67753955e-01, -1.73345939e+00, ...,\n",
       "           -4.10811043e+00, -5.09897704e+00, -6.32370551e+00],\n",
       "          [-5.58830104e-02,  1.30402385e-01, -4.47095753e-01, ...,\n",
       "           -3.88133300e+00, -4.71683983e+00, -5.94200147e+00]],\n",
       " \n",
       "         [[-4.16995623e-01,  5.16278782e-01, -1.19142770e+00, ...,\n",
       "           -3.02323440e+00, -3.67275803e+00, -3.82049422e+00],\n",
       "          [-1.28454649e+00,  9.73121818e-02, -1.82950950e+00, ...,\n",
       "           -4.58544332e+00, -5.29544721e+00, -5.50019613e+00],\n",
       "          [ 1.95577935e-01,  2.93365924e-01, -2.93371792e-01, ...,\n",
       "           -3.79914176e+00, -4.50459827e+00, -4.80996382e+00],\n",
       "          ...,\n",
       "          [-1.49115372e+00,  1.67753955e-01, -1.73345939e+00, ...,\n",
       "           -4.10811043e+00, -5.09897704e+00, -6.32370551e+00],\n",
       "          [-5.58830104e-02,  1.30402385e-01, -4.47095753e-01, ...,\n",
       "           -3.88133300e+00, -4.71683983e+00, -5.94200147e+00],\n",
       "          [ 9.32140211e-02,  3.54218873e-01, -3.72856085e-01, ...,\n",
       "           -3.57475644e+00, -4.23042408e+00, -5.43996933e+00]],\n",
       " \n",
       "         [[-1.28454649e+00,  9.73121818e-02, -1.82950950e+00, ...,\n",
       "           -4.58544332e+00, -5.29544721e+00, -5.50019613e+00],\n",
       "          [ 1.95577935e-01,  2.93365924e-01, -2.93371792e-01, ...,\n",
       "           -3.79914176e+00, -4.50459827e+00, -4.80996382e+00],\n",
       "          [-7.76853728e-01,  2.71895503e-01, -1.10701880e+00, ...,\n",
       "           -4.00563453e+00, -4.81336408e+00, -5.28452389e+00],\n",
       "          ...,\n",
       "          [-5.58830104e-02,  1.30402385e-01, -4.47095753e-01, ...,\n",
       "           -3.88133300e+00, -4.71683983e+00, -5.94200147e+00],\n",
       "          [ 9.32140211e-02,  3.54218873e-01, -3.72856085e-01, ...,\n",
       "           -3.57475644e+00, -4.23042408e+00, -5.43996933e+00],\n",
       "          [ 3.55542671e-01,  7.29796047e-01, -1.30988026e-01, ...,\n",
       "           -2.98184460e+00, -3.48802017e+00, -4.63322983e+00]]]]),\n",
       " 'support_labels': array([[ 6.83310994, -1.18900784,  1.49377178,  0.77678253, -0.60851927],\n",
       "        [-1.18900784,  1.49377178,  0.77678253, -0.60851927, -5.10204082],\n",
       "        [ 1.49377178,  0.77678253, -0.60851927, -5.10204082,  7.74193118],\n",
       "        ...,\n",
       "        [ 0.39689851, -0.28237576,  1.28374738,  0.05591426, -0.07451751],\n",
       "        [-0.28237576,  1.28374738,  0.05591426, -0.07451751, -0.37285608],\n",
       "        [ 1.28374738,  0.05591426, -0.07451751, -0.37285608,  0.56138287]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_test_mix.all_tasks[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3d04d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_stock(p: Path | str):\n",
    "        def longterm_trend(x: pd.Series, k:int):\n",
    "            return (x.rolling(k).sum().div(k*x) - 1) * 100\n",
    "\n",
    "        df = pd.read_csv(p)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.sort_values('Date').reset_index(drop=True)\n",
    "        if 'Unnamed' in df.columns:\n",
    "            df.drop(columns=df.columns[7], inplace=True)\n",
    "        if 'Original_Open' in df.columns:\n",
    "            df.rename(columns={'Original_Open': 'Open', 'Open': 'Adj Open'}, inplace=True)\n",
    "\n",
    "        # Open, High, Low\n",
    "        z1 = (df.loc[:, ['Open', 'High', 'Low']].div(df['Close'], axis=0) - 1).rename(\n",
    "            columns={'Open': 'open', 'High': 'high', 'Low': 'low'}) * 100\n",
    "        # Close\n",
    "        z2 = df[['Close']].pct_change().rename(columns={'Close': 'close'}) * 100\n",
    "        # Adj Close\n",
    "        z3 = df[['Adj Close']].pct_change().rename(columns={'Adj Close': 'adj_close'}) * 100\n",
    "\n",
    "        z4 = []\n",
    "        for k in [5, 10, 15, 20, 25, 30]:\n",
    "            z4.append(df[['Adj Close']].apply(longterm_trend, k=k).rename(columns={'Adj Close': f'zd{k}'}))\n",
    "\n",
    "        df_pct = pd.concat([df['Date'], z1, z2, z3] + z4, axis=1).rename(columns={'Date': 'date'})\n",
    "        cols_max = df_pct.columns[df_pct.isnull().sum() == df_pct.isnull().sum().max()]\n",
    "        df_pct = df_pct.loc[~df_pct[cols_max].isnull().values, :]\n",
    "\n",
    "        return df_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecdc16e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/david/yjhwang/TEAP/data/kdd17/price_long_50')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_config['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d431a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = list((ds_config['path']).glob('*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5626e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ceafa564",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_2 = ps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eaa32091",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbol = p.name.rstrip('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2e4a5802",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbol_2 = p_2.name.rstrip('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "24fe48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = [p,p_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d245e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = load_single_stock(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b001eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = load_single_stock(p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f0cf7223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2489, 12)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f5ef2529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2489, 12)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d1f90ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_idx(df_single, window_size, n_support, n_query):\n",
    "    if len(df_single) >= window_size:\n",
    "        x_spt_task = []\n",
    "        y_spt_task = []\n",
    "        x_qry_task = []\n",
    "        y_qry_task = []\n",
    "\n",
    "        for i in range(len_df-window_size-n_support-n_query+1):\n",
    "            x_spt = []\n",
    "            y_spt = []\n",
    "            x_qry = []\n",
    "            y_qry = []\n",
    "\n",
    "            for j in range(n_support+n_query):\n",
    "                if j < n_support:\n",
    "                    spt_idx = [idx for idx in range(i+j, i+j+window_size)]\n",
    "                    x_spt.append(spt_idx)\n",
    "                    y_spt.append(i+j+window_size)\n",
    "\n",
    "                else:\n",
    "                    qry_idx = [idx for idx in range(i+j, i+j+window_size)]\n",
    "                    x_qry.append(qry_idx)\n",
    "                    y_qry.append(i+j+window_size)\n",
    "\n",
    "            x_spt_task.append(x_spt)\n",
    "            y_spt_task.append(y_spt)\n",
    "            x_qry_task.append(x_qry)\n",
    "            y_qry_task.append(y_qry)\n",
    "        return x_spt_task, y_spt_task, x_qry_task, y_qry_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e6c47422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(df_single, x_spt_task, y_spt_task, x_qry_task, y_qry_task, n_support, n_query):\n",
    "    num_task = len(x_spt_task)\n",
    "    support_task = []\n",
    "    support_labels = []\n",
    "    query_task = []\n",
    "    query_labels = []\n",
    "    for i in range(len(x_spt_task)):\n",
    "        support_inputs = []\n",
    "        query_inputs = []\n",
    "        for j in range(n_support):\n",
    "            support_inputs.append(df_single.iloc[x_spt_task[i][j]].to_numpy()[:, 1:].astype(np.float64))\n",
    "        \n",
    "        support_labels.append(df_single['close'].iloc[y_spt_task[i]].to_numpy().astype(np.float64))\n",
    "        support_task.append(np.array(support_inputs))\n",
    "        for k in range(n_query):\n",
    "            query_inputs.append(df_single.iloc[x_qry_task[i][k]].to_numpy()[:, 1:].astype(np.float64))\n",
    "        query_labels.append(df_single['close'].iloc[y_qry_task[i]].to_numpy().astype(np.float64))\n",
    "        query_task.append(np.array(query_inputs))   \n",
    "        \n",
    "    return support_task, support_labels, query_task, query_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "70b69cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size, n_support, n_query = 3, 5, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8eb04de3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_spt_task, y_spt_task, x_qry_task, y_qry_task = sliding_window_idx(df_2, window_size, n_support, n_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ea9e6084",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_inputs, support_labels, query_inputs, query_labels = generate_data(df_2, x_spt_task, y_spt_task, x_qry_task, y_qry_task, n_support, n_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "aa902814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support input: 12\n",
      "support label: 12\n",
      "query input: 12\n",
      "query label: 12\n"
     ]
    }
   ],
   "source": [
    "print(f'support input: {len(support_inputs)}') # (n_task, n_support, widow_size, feature_dim)\n",
    "print(f'support label: {len(support_labels)}') # (n_task, n_support)\n",
    "print(f'query input: {len(query_inputs)}')\n",
    "print(f'query label: {len(query_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "46968795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 11)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a154ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fcd51cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.26134388,  3.84167883,  0.34753364, -0.49156072, -0.62871896])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4ac2eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = dict(\n",
    "            query = [],\n",
    "            query_labels = [],\n",
    "            support = [],\n",
    "            support_labels = [],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a2222285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_task(symbol):\n",
    "    all_tasks = dict(\n",
    "            query = [],\n",
    "            query_labels = [],\n",
    "            support = [],\n",
    "            support_labels = [],\n",
    "        )\n",
    "    for s in symbol:\n",
    "        df = load_single_stock(s)\n",
    "        x_spt_task, y_spt_task, x_qry_task, y_qry_task = sliding_window_idx(df, window_size, n_support, n_query)\n",
    "        support_inputs, support_labels, query_inputs, query_labels = generate_data(df, x_spt_task, y_spt_task, x_qry_task, y_qry_task, n_support, n_query)\n",
    "        all_tasks['query'].extend(query_inputs)\n",
    "        all_tasks['query_labels'].extend(query_labels)\n",
    "        all_tasks['support'].extend(support_inputs)\n",
    "        all_tasks['support_labels'].extend(support_labels)\n",
    "        num_task = len(all_tasks['query'])\n",
    "    return num_task, all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bd4f8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_task(batch_size, all_tasks, num_task):\n",
    "    batch_tasks = dict(\n",
    "            query = [],\n",
    "            query_labels = [],\n",
    "            support = [],\n",
    "            support_labels = [],\n",
    "        )\n",
    "    for k, v in all_tasks.items():\n",
    "            all_tasks[k] = np.array(v)\n",
    "            \n",
    "    batch_idx = random.sample(list(range(num_task)), batch_size)\n",
    "    batch_tasks['query'] = all_tasks['query'][batch_idx]\n",
    "    batch_tasks['query_labels'] = all_tasks['query_labels'][batch_idx]\n",
    "    batch_tasks['support'] = all_tasks['support'][batch_idx]\n",
    "    batch_tasks['support_labels'] = all_tasks['support_labels'][batch_idx]\n",
    "    \n",
    "    return batch_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e30dc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_task, all_tasks = generate_all_task(symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7d534598",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tasks = generate_batch_task(batch_size=2, all_tasks=all_tasks, num_task=num_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bb8133cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockRegressionDataDict(dict):\n",
    "    def __init__(self, data, window_size):\n",
    "        self.window_size = window_size\n",
    "        self._set_state(f'numpy')\n",
    "        for k, v in data.items():\n",
    "            data[k] = np.array(v)\n",
    "        \n",
    "        self.n_stocks = len(v)\n",
    "        super().__init__(data)\n",
    "    \n",
    "    def tensor_fn(self, value, key):\n",
    "        return torch.FloatTensor(value)\n",
    "\n",
    "    def _set_state(self, state: str):\n",
    "        self.state = state\n",
    "\n",
    "    def to(self, device: None | str=None):\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        else:\n",
    "            device = torch.device(device)\n",
    "        self._set_state(f'tensor.{device}')\n",
    "        for key in self.keys():\n",
    "            value = self.__getitem__(key)\n",
    "            tvalue = self.tensor_fn(value, key)\n",
    "            self.__setitem__(key, tvalue.to(device)) \n",
    "        \n",
    "    def numpy(self):\n",
    "        self._set_state('numpy')\n",
    "        for key in self.keys():\n",
    "            tvalue = self.__getitem__(key)\n",
    "            if not isinstance(tvalue, np.ndarray): \n",
    "                self.__setitem__(key, tvalue.detach().numpy())\n",
    "\n",
    "    def __str__(self):\n",
    "        s = f'StockDataDict(T={self.window_size}, {self.state})\\n'\n",
    "        for i, key in enumerate(self.keys()):\n",
    "            value = self.__getitem__(key)\n",
    "            s += f'- {key}: {value.shape}'\n",
    "            s += '' if i == len(self.keys())-1 else '\\n'\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "67f44378",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = StockRegressionDataDict(batch_tasks, window_size = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9faadad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9ce3e2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': tensor([[[[-0.5876,  1.1242, -2.7082,  0.7983,  0.7983,  2.5192,  3.2013,\n",
       "             2.0082,  0.6745, -0.4854, -1.2936],\n",
       "           [ 1.2098,  1.2098, -2.0592, -0.7409, -0.7409,  2.1776,  3.6396,\n",
       "             2.7473,  1.5779,  0.4211, -0.4736],\n",
       "           [ 1.6715,  3.1308,  0.0000, -2.9858, -2.9858,  3.6827,  6.2006,\n",
       "             5.6602,  4.5702,  3.5765,  2.6523]]],\n",
       " \n",
       " \n",
       "         [[[-3.4804,  1.4358, -3.8020,  2.8956,  2.8956, -0.4870, -0.3182,\n",
       "            -1.0522, -1.4536, -1.4592, -1.1601],\n",
       "           [ 1.5923,  2.4939, -0.2342, -1.8952, -1.8953,  0.5784,  1.6310,\n",
       "             0.7993,  0.4894,  0.4051,  0.6065],\n",
       "           [-0.4981,  2.6993, -0.6487,  1.0655,  1.0655, -0.9893,  0.7322,\n",
       "            -0.0278, -0.4790, -0.6098, -0.5383]]]], device='cuda:0'),\n",
       " 'query_labels': tensor([[-1.6981],\n",
       "         [ 2.1664]], device='cuda:0'),\n",
       " 'support': tensor([[[[-0.1697,  0.1454, -0.8240, -0.6023, -0.6023, -1.4542, -3.4755,\n",
       "            -5.0816, -6.3112, -7.0887, -7.2895],\n",
       "           [ 0.9756,  2.4390, -0.2683, -0.6301, -0.6301, -0.4098, -2.3707,\n",
       "            -3.9382, -5.2610, -6.1951, -6.4398],\n",
       "           [ 0.5395,  1.0299, -0.0981, -0.5366, -0.5366,  0.4806, -1.4321,\n",
       "            -3.0799, -4.2962, -5.3163, -5.6384]],\n",
       " \n",
       "          [[ 0.9756,  2.4390, -0.2683, -0.6301, -0.6301, -0.4098, -2.3707,\n",
       "            -3.9382, -5.2610, -6.1951, -6.4398],\n",
       "           [ 0.5395,  1.0299, -0.0981, -0.5366, -0.5366,  0.4806, -1.4321,\n",
       "            -3.0799, -4.2962, -5.3163, -5.6384],\n",
       "           [-0.0489,  0.7828, -1.1742,  0.2452,  0.2452,  0.5039, -1.1448,\n",
       "            -2.7479, -4.0374, -5.1703, -5.5855]],\n",
       " \n",
       "          [[ 0.5395,  1.0299, -0.0981, -0.5366, -0.5366,  0.4806, -1.4321,\n",
       "            -3.0799, -4.2962, -5.3163, -5.6384],\n",
       "           [-0.0489,  0.7828, -1.1742,  0.2452,  0.2452,  0.5039, -1.1448,\n",
       "            -2.7479, -4.0374, -5.1703, -5.5855],\n",
       "           [ 3.5024,  4.4038, -0.1288, -5.0147, -5.0147,  4.4296,  4.0690,\n",
       "             2.6732,  1.2091,  0.0299, -0.5468]],\n",
       " \n",
       "          [[-0.0489,  0.7828, -1.1742,  0.2452,  0.2452,  0.5039, -1.1448,\n",
       "            -2.7479, -4.0374, -5.1703, -5.5855],\n",
       "           [ 3.5024,  4.4038, -0.1288, -5.0147, -5.0147,  4.4296,  4.0690,\n",
       "             2.6732,  1.2091,  0.0299, -0.5468],\n",
       "           [-0.5876,  1.1242, -2.7082,  0.7983,  0.7983,  2.5192,  3.2013,\n",
       "             2.0082,  0.6745, -0.4854, -1.2936]],\n",
       " \n",
       "          [[ 3.5024,  4.4038, -0.1288, -5.0147, -5.0147,  4.4296,  4.0690,\n",
       "             2.6732,  1.2091,  0.0299, -0.5468],\n",
       "           [-0.5876,  1.1242, -2.7082,  0.7983,  0.7983,  2.5192,  3.2013,\n",
       "             2.0082,  0.6745, -0.4854, -1.2936],\n",
       "           [ 1.2098,  1.2098, -2.0592, -0.7409, -0.7409,  2.1776,  3.6396,\n",
       "             2.7473,  1.5779,  0.4211, -0.4736]]],\n",
       " \n",
       " \n",
       "         [[[ 1.4412,  1.4524, -1.0949,  0.3475,  0.3475, -2.8824, -4.0353,\n",
       "            -4.4643, -4.3928, -3.9964, -2.1417],\n",
       "           [ 0.1010,  1.4258, -0.2470, -0.4916, -0.4916, -1.5359, -3.2368,\n",
       "            -3.6683, -3.7622, -3.5222, -1.9550],\n",
       "           [ 1.5027,  1.6834, -1.0168, -0.6287, -0.6287, -0.0814, -2.0325,\n",
       "            -2.7756, -2.9765, -2.9113, -1.6092]],\n",
       " \n",
       "          [[ 0.1010,  1.4258, -0.2470, -0.4916, -0.4916, -1.5359, -3.2368,\n",
       "            -3.6683, -3.7622, -3.5222, -1.9550],\n",
       "           [ 1.5027,  1.6834, -1.0168, -0.6287, -0.6287, -0.0814, -2.0325,\n",
       "            -2.7756, -2.9765, -2.9113, -1.6092],\n",
       "           [ 2.8238,  3.7531, -0.6196, -5.1746, -5.1746,  4.9017,  3.2003,\n",
       "             2.5291,  2.1983,  2.2504,  3.3353]],\n",
       " \n",
       "          [[ 1.5027,  1.6834, -1.0168, -0.6287, -0.6287, -0.0814, -2.0325,\n",
       "            -2.7756, -2.9765, -2.9113, -1.6092],\n",
       "           [ 2.8238,  3.7531, -0.6196, -5.1746, -5.1746,  4.9017,  3.2003,\n",
       "             2.5291,  2.1983,  2.2504,  3.3353],\n",
       "           [-1.9029,  1.1701, -1.9029,  0.8102,  0.8102,  2.9736,  2.3602,\n",
       "             1.7413,  1.3214,  1.3771,  2.0128]],\n",
       " \n",
       "          [[ 2.8238,  3.7531, -0.6196, -5.1746, -5.1746,  4.9017,  3.2003,\n",
       "             2.5291,  2.1983,  2.2504,  3.3353],\n",
       "           [-1.9029,  1.1701, -1.9029,  0.8102,  0.8102,  2.9736,  2.3602,\n",
       "             1.7413,  1.3214,  1.3771,  2.0128],\n",
       "           [-3.4804,  1.4358, -3.8020,  2.8956,  2.8956, -0.4870, -0.3182,\n",
       "            -1.0522, -1.4536, -1.4592, -1.1601]],\n",
       " \n",
       "          [[-1.9029,  1.1701, -1.9029,  0.8102,  0.8102,  2.9736,  2.3602,\n",
       "             1.7413,  1.3214,  1.3771,  2.0128],\n",
       "           [-3.4804,  1.4358, -3.8020,  2.8956,  2.8956, -0.4870, -0.3182,\n",
       "            -1.0522, -1.4536, -1.4592, -1.1601],\n",
       "           [ 1.5923,  2.4939, -0.2342, -1.8952, -1.8953,  0.5784,  1.6310,\n",
       "             0.7993,  0.4894,  0.4051,  0.6065]]]], device='cuda:0'),\n",
       " 'support_labels': tensor([[ 0.2452, -5.0147,  0.7983, -0.7409, -2.9858],\n",
       "         [-5.1746,  0.8102,  2.8956, -1.8952,  1.0655]], device='cuda:0')}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a29d75b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StockDataDict(T=3, tensor.cuda)\n",
      "- query: torch.Size([2, 1, 3, 11])\n",
      "- query_labels: torch.Size([2, 1])\n",
      "- support: torch.Size([2, 5, 3, 11])\n",
      "- support_labels: torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d5b112e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 3, 11)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tasks['query'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "43e94c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tasks['query_labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d968b6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch_tasks['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2f1235b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(batch_tasks['query_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d16d1777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tasks['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f22e7262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 3, 11)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tasks['support'][[1,2,3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c48230de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(all_tasks['support']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "efb1738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_fn(value, key):\n",
    "    return torch.FloatTensor(value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "77c7fb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 5, 3, 11])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(all_tasks['support']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3e95b730",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "for key,value in batch_tasks.items():\n",
    "            tvalue = tensor_fn(value, key)\n",
    "            batch_tasks[key] = tvalue.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "35bb09d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': tensor([[[[ 1.2098,  1.2098, -2.0592, -0.7409, -0.7409,  2.1776,  3.6396,\n",
       "             2.7473,  1.5779,  0.4211, -0.4736],\n",
       "           [ 1.6715,  3.1308,  0.0000, -2.9858, -2.9858,  3.6827,  6.2006,\n",
       "             5.6602,  4.5702,  3.5765,  2.6523],\n",
       "           [ 0.2699,  3.4278, -0.0270, -1.6981, -1.6981,  3.4062,  7.1498,\n",
       "             7.1849,  6.3306,  5.3873,  4.4283]]],\n",
       " \n",
       " \n",
       "         [[[ 0.9756,  2.4390, -0.2683, -0.6301, -0.6301, -0.4098, -2.3707,\n",
       "            -3.9382, -5.2610, -6.1951, -6.4398],\n",
       "           [ 0.5395,  1.0299, -0.0981, -0.5366, -0.5366,  0.4806, -1.4321,\n",
       "            -3.0799, -4.2962, -5.3163, -5.6384],\n",
       "           [-0.0489,  0.7828, -1.1742,  0.2452,  0.2452,  0.5039, -1.1448,\n",
       "            -2.7479, -4.0374, -5.1703, -5.5855]]]], device='cuda:0'),\n",
       " 'query_labels': tensor([[ 4.1296],\n",
       "         [-5.0147]], device='cuda:0'),\n",
       " 'support': tensor([[[[ 0.9756,  2.4390, -0.2683, -0.6301, -0.6301, -0.4098, -2.3707,\n",
       "            -3.9382, -5.2610, -6.1951, -6.4398],\n",
       "           [ 0.5395,  1.0299, -0.0981, -0.5366, -0.5366,  0.4806, -1.4321,\n",
       "            -3.0799, -4.2962, -5.3163, -5.6384],\n",
       "           [-0.0489,  0.7828, -1.1742,  0.2452,  0.2452,  0.5039, -1.1448,\n",
       "            -2.7479, -4.0374, -5.1703, -5.5855]],\n",
       " \n",
       "          [[ 0.5395,  1.0299, -0.0981, -0.5366, -0.5366,  0.4806, -1.4321,\n",
       "            -3.0799, -4.2962, -5.3163, -5.6384],\n",
       "           [-0.0489,  0.7828, -1.1742,  0.2452,  0.2452,  0.5039, -1.1448,\n",
       "            -2.7479, -4.0374, -5.1703, -5.5855],\n",
       "           [ 3.5024,  4.4038, -0.1288, -5.0147, -5.0147,  4.4296,  4.0690,\n",
       "             2.6732,  1.2091,  0.0299, -0.5468]],\n",
       " \n",
       "          [[-0.0489,  0.7828, -1.1742,  0.2452,  0.2452,  0.5039, -1.1448,\n",
       "            -2.7479, -4.0374, -5.1703, -5.5855],\n",
       "           [ 3.5024,  4.4038, -0.1288, -5.0147, -5.0147,  4.4296,  4.0690,\n",
       "             2.6732,  1.2091,  0.0299, -0.5468],\n",
       "           [-0.5876,  1.1242, -2.7082,  0.7983,  0.7983,  2.5192,  3.2013,\n",
       "             2.0082,  0.6745, -0.4854, -1.2936]],\n",
       " \n",
       "          [[ 3.5024,  4.4038, -0.1288, -5.0147, -5.0147,  4.4296,  4.0690,\n",
       "             2.6732,  1.2091,  0.0299, -0.5468],\n",
       "           [-0.5876,  1.1242, -2.7082,  0.7983,  0.7983,  2.5192,  3.2013,\n",
       "             2.0082,  0.6745, -0.4854, -1.2936],\n",
       "           [ 1.2098,  1.2098, -2.0592, -0.7409, -0.7409,  2.1776,  3.6396,\n",
       "             2.7473,  1.5779,  0.4211, -0.4736]],\n",
       " \n",
       "          [[-0.5876,  1.1242, -2.7082,  0.7983,  0.7983,  2.5192,  3.2013,\n",
       "             2.0082,  0.6745, -0.4854, -1.2936],\n",
       "           [ 1.2098,  1.2098, -2.0592, -0.7409, -0.7409,  2.1776,  3.6396,\n",
       "             2.7473,  1.5779,  0.4211, -0.4736],\n",
       "           [ 1.6715,  3.1308,  0.0000, -2.9858, -2.9858,  3.6827,  6.2006,\n",
       "             5.6602,  4.5702,  3.5765,  2.6523]]],\n",
       " \n",
       " \n",
       "         [[[-2.2671,  0.3488, -2.4913,  2.1114,  2.1114, -2.2820, -3.6821,\n",
       "            -4.8829, -5.6627, -5.6672, -5.5074],\n",
       "           [ 0.1997,  0.6490, -0.4993, -0.1993, -0.1993, -1.6076, -3.1503,\n",
       "            -4.1970, -5.0899, -5.1882, -5.2055],\n",
       "           [-1.0662,  0.2727, -1.1406,  0.6740,  0.6740, -1.4679, -3.0697,\n",
       "            -4.2632, -5.3149, -5.5324, -5.7220]],\n",
       " \n",
       "          [[ 0.1997,  0.6490, -0.4993, -0.1993, -0.1993, -1.6076, -3.1503,\n",
       "            -4.1970, -5.0899, -5.1882, -5.2055],\n",
       "           [-1.0662,  0.2727, -1.1406,  0.6740,  0.6740, -1.4679, -3.0697,\n",
       "            -4.2632, -5.3149, -5.5324, -5.7220],\n",
       "           [-3.3245,  0.5541, -3.6377,  2.9259,  2.9259, -2.9872, -4.7772,\n",
       "            -6.3294, -7.4572, -7.8988, -8.1498]],\n",
       " \n",
       "          [[-1.0662,  0.2727, -1.1406,  0.6740,  0.6740, -1.4679, -3.0697,\n",
       "            -4.2632, -5.3149, -5.5324, -5.7220],\n",
       "           [-3.3245,  0.5541, -3.6377,  2.9259,  2.9259, -2.9872, -4.7772,\n",
       "            -6.3294, -7.4572, -7.8988, -8.1498],\n",
       "           [-0.1697,  0.1454, -0.8240, -0.6023, -0.6023, -1.4542, -3.4755,\n",
       "            -5.0816, -6.3112, -7.0887, -7.2895]],\n",
       " \n",
       "          [[-3.3245,  0.5541, -3.6377,  2.9259,  2.9259, -2.9872, -4.7772,\n",
       "            -6.3294, -7.4572, -7.8988, -8.1498],\n",
       "           [-0.1697,  0.1454, -0.8240, -0.6023, -0.6023, -1.4542, -3.4755,\n",
       "            -5.0816, -6.3112, -7.0887, -7.2895],\n",
       "           [ 0.9756,  2.4390, -0.2683, -0.6301, -0.6301, -0.4098, -2.3707,\n",
       "            -3.9382, -5.2610, -6.1951, -6.4398]],\n",
       " \n",
       "          [[-0.1697,  0.1454, -0.8240, -0.6023, -0.6023, -1.4542, -3.4755,\n",
       "            -5.0816, -6.3112, -7.0887, -7.2895],\n",
       "           [ 0.9756,  2.4390, -0.2683, -0.6301, -0.6301, -0.4098, -2.3707,\n",
       "            -3.9382, -5.2610, -6.1951, -6.4398],\n",
       "           [ 0.5395,  1.0299, -0.0981, -0.5366, -0.5366,  0.4806, -1.4321,\n",
       "            -3.0799, -4.2962, -5.3163, -5.6384]]]], device='cuda:0'),\n",
       " 'support_labels': tensor([[-5.0147,  0.7983, -0.7409, -2.9858, -1.6981],\n",
       "         [ 2.9259, -0.6023, -0.6301, -0.5366,  0.2452]], device='cuda:0')}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a2b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to(device: None | str=None):\n",
    "        if device is None:\n",
    "            device = torch.device('cpu')\n",
    "        else:\n",
    "            device = torch.device(device)\n",
    "\n",
    "        for key in all_tasks.keys():\n",
    "            tvalue = tensor_fn(value, key)\n",
    "            self.__setitem__(key, tvalue.to(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e7105ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3, 11)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tasks['support'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4b9e45f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 11)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tasks['query'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f50810db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_spt_task:[[[0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6]], [[1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7]]]\n",
      "y_spt_task: [[3, 4, 5, 6, 7], [4, 5, 6, 7, 8]]\n"
     ]
    }
   ],
   "source": [
    "print(f'x_spt_task:{x_spt_task[:2]}')\n",
    "print(f'y_spt_task: {y_spt_task[:2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d9c3de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_spt_task[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "340c916f",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_inputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22e3a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_inputs.append(df_single.iloc[x_spt_task[0][0]].to_numpy()[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e3bf60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 11)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(support_inputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3b1b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "24994136",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_labels.append(df_single['close'].iloc[y_spt_task[0]].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "096a8356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.26134388,  3.84167883,  0.34753364, -0.49156072, -0.62871896]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(support_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14cc7d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(support_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4673279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_qry_task:[[[5, 6, 7]], [[6, 7, 8]]]\n",
      "y_qry_task: [[8], [9]]\n"
     ]
    }
   ],
   "source": [
    "print(f'x_qry_task:{x_qry_task[:2]}')\n",
    "print(f'y_qry_task: {y_qry_task[:2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3f78c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,window_size = 0,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6c6daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spt_idx = [idx for idx in range(i, i+window_size)]\n",
    "spt_label_idx =  [spt_idx[-1] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efcac814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4], [5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spt_idx, spt_label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bcf1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = 20\n",
    "window_size = 2\n",
    "n_support = 3\n",
    "n_query = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1a8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_spt_task = []\n",
    "y_spt_task = []\n",
    "x_qry_task = []\n",
    "y_qry_task = []\n",
    "\n",
    "for i in range(len_df-window_size-n_support-n_query+1):\n",
    "    x_spt = []\n",
    "    y_spt = []\n",
    "    x_qry = []\n",
    "    y_qry = []\n",
    "    \n",
    "    for j in range(n_support+n_query):\n",
    "        if j < n_support:\n",
    "            spt_idx = [idx for idx in range(i+j, i+j+window_size)]\n",
    "            x_spt.append(spt_idx)\n",
    "            y_spt.append(i+j+window_size)\n",
    "           \n",
    "        else:\n",
    "            qry_idx = [idx for idx in range(i+j, i+j+window_size)]\n",
    "            x_qry.append(qry_idx)\n",
    "            y_qry.append(i+j+window_size)\n",
    "\n",
    "    x_spt_task.append(x_spt)\n",
    "    y_spt_task.append(y_spt)\n",
    "    x_qry_task.append(x_qry)\n",
    "    y_qry_task.append(y_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92eb363",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 1], [1, 2], [2, 3]],\n",
       " [[1, 2], [2, 3], [3, 4]],\n",
       " [[2, 3], [3, 4], [4, 5]],\n",
       " [[3, 4], [4, 5], [5, 6]],\n",
       " [[4, 5], [5, 6], [6, 7]],\n",
       " [[5, 6], [6, 7], [7, 8]],\n",
       " [[6, 7], [7, 8], [8, 9]],\n",
       " [[7, 8], [8, 9], [9, 10]],\n",
       " [[8, 9], [9, 10], [10, 11]],\n",
       " [[9, 10], [10, 11], [11, 12]],\n",
       " [[10, 11], [11, 12], [12, 13]],\n",
       " [[11, 12], [12, 13], [13, 14]],\n",
       " [[12, 13], [13, 14], [14, 15]],\n",
       " [[13, 14], [14, 15], [15, 16]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_spt_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6162a226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4],\n",
       " [3, 4, 5],\n",
       " [4, 5, 6],\n",
       " [5, 6, 7],\n",
       " [6, 7, 8],\n",
       " [7, 8, 9],\n",
       " [8, 9, 10],\n",
       " [9, 10, 11],\n",
       " [10, 11, 12],\n",
       " [11, 12, 13],\n",
       " [12, 13, 14],\n",
       " [13, 14, 15],\n",
       " [14, 15, 16],\n",
       " [15, 16, 17]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_spt_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9580efd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[3, 4], [4, 5]],\n",
       " [[4, 5], [5, 6]],\n",
       " [[5, 6], [6, 7]],\n",
       " [[6, 7], [7, 8]],\n",
       " [[7, 8], [8, 9]],\n",
       " [[8, 9], [9, 10]],\n",
       " [[9, 10], [10, 11]],\n",
       " [[10, 11], [11, 12]],\n",
       " [[11, 12], [12, 13]],\n",
       " [[12, 13], [13, 14]],\n",
       " [[13, 14], [14, 15]],\n",
       " [[14, 15], [15, 16]],\n",
       " [[15, 16], [16, 17]],\n",
       " [[16, 17], [17, 18]]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_qry_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8539c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d9a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
